{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Monitoring Kubernetes with Prometheus \u2014 A Personal Project","text":"<p>Welcome to my Prometheus on Kubernetes documentation project \u2014 a personal initiative to showcase deep expertise in monitoring, observability, and cloud-native systems at scale.</p> <p>This site is structured as a complete guide to running Prometheus in Kubernetes, blending fundamentals, hands-on examples, best practices, and advanced topics. It is designed for engineers, SREs, and learners who want to understand Kubernetes monitoring from zero to production-grade scale.</p>"},{"location":"#project-purpose","title":"Project Purpose","text":"<ul> <li>Demonstrate expert knowledge in Prometheus, Kubernetes, and cloud-native observability.</li> <li>Provide a world-class learning resource tailored to Kubernetes users, assuming no prior experience.</li> <li>Serve as a portfolio piece highlighting my skills in technical writing, system design, and DevOps practices.</li> </ul>"},{"location":"#quick-overview-of-prometheus-on-kubernetes","title":"Quick Overview of Prometheus on Kubernetes","text":"<p>Prometheus is the de-facto monitoring and alerting toolkit in Kubernetes that:</p> <ul> <li>Collects metrics from nodes, pods, and services via service discovery.</li> <li>Stores them in a purpose-built time-series database (TSDB).</li> <li>Uses PromQL to query cluster and application metrics.</li> <li>Sends alerts via Alertmanager.</li> <li>Integrates seamlessly with Grafana for dashboards.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Jump into the Quick Start guide to see Kubernetes monitoring in action:</p> <ul> <li>Deploy Prometheus on Kubernetes (Helm, Operator, or manifests).</li> <li>Scrape metrics from nodes, pods, and system components.</li> <li>Query cluster data using PromQL.</li> <li>Build dashboards in Grafana.</li> <li>Configure a basic alert in Alertmanager.</li> </ul>"},{"location":"#architecture-components","title":"Architecture &amp; Components","text":"<p>This project explains Kubernetes monitoring from the ground up:</p> <ul> <li>Core Concepts \u2192 Metrics, exporters, service discovery, labels.</li> <li>Prometheus Server \u2192 Scraping workloads and cluster components.</li> <li>Alertmanager \u2192 Routing and managing cluster alerts.</li> <li>Grafana \u2192 Visualizing cluster health and application metrics.</li> <li>Scaling \u2192 Prometheus Operator, Thanos, Cortex, federation, long-term storage.</li> </ul> <p>See detailed workflows in Architecture.</p>"},{"location":"#documentation-roadmap","title":"Documentation Roadmap","text":"<p>The guide follows a step-by-step learning path:</p> <ul> <li>Quick Start \u2192 Deploy Prometheus in Kubernetes and scrape your first metrics.</li> <li>Architecture \u2192 Understand internals, exporters, and service discovery.</li> <li>PromQL &amp; Features \u2192 Querying cluster/app data, defining alerts.</li> <li>Scaling &amp; Best Practices \u2192 HA setups, long-term storage, high-cardinality strategies.</li> <li>About Me \u2192 My background, expertise, and contact info.</li> </ul>"},{"location":"#example-use-cases","title":"Example Use Cases","text":"<p>Prometheus in Kubernetes enables:</p> <ul> <li>Cluster Monitoring \u2192 Node health, kubelet, API server, etcd.</li> <li>Workload Monitoring \u2192 Pod metrics, deployments, HPA scaling signals.</li> <li>Application Monitoring \u2192 Service SLIs, latency, error rates, traffic.</li> <li>Alerting \u2192 Node pressure, pod crashes, SLA breaches, anomalies.</li> </ul> <p>All use cases are illustrated with hands-on Kubernetes demos.</p>"},{"location":"#useful-links","title":"Useful Links","text":"<ul> <li>Getting Started</li> <li>System Architecture</li> <li>PromQL &amp; Features</li> <li>About Me</li> </ul>"},{"location":"#about-this-project","title":"About This Project","text":"<p>This documentation is a personal showcase of Kubernetes monitoring expertise. It combines:</p> <ul> <li>Deep Kubernetes integration knowledge</li> <li>Hands-on best practices with Prometheus Operator &amp; exporters</li> <li>Clear explanations for beginners and advanced practitioners</li> </ul> <p>License: MIT</p> <p>Maintained by Sean Njela.</p>"},{"location":"disclaimer/","title":"Disclaimer","text":"<p>The information and resources provided in this project are intended for educational and informational purposes only.</p>"},{"location":"disclaimer/#no-warranty","title":"No Warranty","text":"<p>This project is provided \"as is\" without warranty of any kind\u2014express or implied. While I have made every effort to ensure the accuracy and reliability of the information, I make no guarantees about:</p> <ul> <li>Suitability for any specific purpose  </li> <li>Completeness or accuracy of configurations or scripts  </li> <li>Security of infrastructure or deployments  </li> </ul> <p>Use at your own risk.</p>"},{"location":"disclaimer/#for-personal-use-learning","title":"For Personal Use / Learning","text":"<p>This project is part of a personal portfolio and is primarily intended to:</p> <ul> <li>Demonstrate practical implementation of technical concepts  </li> <li>Serve as a sandbox for experimentation  </li> <li>Be a reference for future personal or professional projects  </li> </ul> <p>It is not intended for production use without proper review and adaptation.</p>"},{"location":"disclaimer/#security-and-sensitive-data","title":"Security and Sensitive Data","text":"<p>Do not reuse any credentials, tokens, secrets, or keys shown in this project. They are either fake, expired, or meant only for demonstration.</p> <p>Always handle secrets securely and follow best practices for secret management (e.g., environment variables, sealed secrets, vaults).</p>"},{"location":"disclaimer/#opinions-are-my-own","title":"Opinions Are My Own","text":"<p>All opinions, techniques, and practices shared here reflect my personal learning journey and are not affiliated with or endorsed by any employer, client, or organization.</p>"},{"location":"disclaimer/#license","title":"License","text":"<p>This project is licensed under the MIT, which permits reuse, modification, and distribution\u2014with proper attribution.</p>"},{"location":"disclaimer/#contact","title":"Contact","text":"<p>If you spot issues, risks, or have questions about how something works, feel free to reach out:</p> <ul> <li>seannjela@outlook.com</li> <li>GitHub Issues</li> </ul>"},{"location":"0-quickstart/0-prerequisites/","title":"Prerequisites","text":"<p>This project uses Devbox to manage the development environment. Devbox provides a consistent, isolated environment with all the necessary CLI tools pre-installed.</p>"},{"location":"0-quickstart/0-prerequisites/#docker","title":"Docker","text":"<ul> <li>Follow the installation instructions for your operating system.</li> </ul> <p>The rest of the tools are already installed in the devbox environment</p>"},{"location":"0-quickstart/0-prerequisites/#devbox","title":"Devbox","text":"<ul> <li>Follow the installation instructions for your operating system.</li> </ul>"},{"location":"0-quickstart/0-prerequisites/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/sean-njela/k8s_monitoring.git\ncd k8s_monitoring\n</code></pre>"},{"location":"0-quickstart/0-prerequisites/#start-the-devbox-environment-and-poetry-environment","title":"Start the Devbox Environment and poetry environment","text":"<pre><code>devbox shell # Start the devbox environment (this will also start the poetry environment)\npoetry install # Install dependencies\npoetry env activate # use the output to activate the poetry environment ( ONLY IF DEVBOX DOES NOT ACTIVATE THE ENVIRONMENT)\n</code></pre> <p>Note</p> <p>The first time you run <code>devbox shell</code>, it will take a few minutes to install the necessary tools. But after that it will be much faster.</p>"},{"location":"0-quickstart/1-getting-started/","title":"Getting Started","text":"<p>Welcome! This section will walk you through how to get the project up and running on your local machine or development environment.</p>"},{"location":"0-quickstart/1-getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed all the requirements. See the Prerequisites section for detailed instructions on installing these tools.</p>"},{"location":"0-quickstart/1-getting-started/#walkthrough","title":"Walkthrough","text":"<p>After everything is wired up, you can run the following commands:</p> <pre><code>task setup\n\ntask status # check if everything is running\n\n# GIVE EVERYTHING A MINUTE TO SETUP THEN\ntask dev\n</code></pre> <p>This will start the devbox environment and poetry environment and install all dependencies. And that is all you need to do to get started. (Yes, really.)</p> <p>In a seperate terminal, run:</p> <pre><code>task docs # serve docs locally\n</code></pre> <p>Docs available at: http://127.0.0.1:8000/</p> <p>All other commands are in the form of tasks. The project task file is <code>Taskfile.yaml</code>.</p> <pre><code>task --list-all # to see all project tasks\ntask &lt;command&gt; # usage\n</code></pre> <p>The project also uses gitflow for version control with gh-pages deployment automation. This is optional but you can also automate it using the <code>Taskfile.gitflow.yaml</code> file.</p> <pre><code>task -t Taskfile.gitflow.yaml --list-all # to see all gitflow tasks\ntask -t Taskfile.gitflow.yaml &lt;command&gt; # usage\n</code></pre> <p>See the Tasks section for more information on all tasks.</p>"},{"location":"0-quickstart/1-getting-started/#cleanup","title":"Cleanup","text":"<p>To tear everything down after testing:</p> <pre><code>task cleanup-dev # to cleanup everything running locally\ntask cleanup-prod # to cleanup everything running in production (IF YOU USED ANY PROD. WORKFLOWS)\ntask cleanup-all # to cleanup everything (local and production)\n</code></pre>"},{"location":"0-quickstart/1-getting-started/#need-help","title":"Need Help?","text":"<p>If you get stuck:</p> <ul> <li>Check the Troubleshooting guide.</li> <li>Open an issue on GitHub</li> </ul> <p>Happy building!</p>"},{"location":"1-architecture/0-overview/","title":"Kubernetes Monitoring Architecture Overview","text":"<p>This section provides a high-level overview of the monitoring and observability stack for Kubernetes. It highlights the core components, their responsibilities, and how they work together to deliver end-to-end monitoring, alerting, and visualization for clusters and workloads.</p>"},{"location":"1-architecture/0-overview/#design-philosophy","title":"Design Philosophy","text":"<p>Our Kubernetes monitoring stack follows these principles:</p> <ul> <li>Modular and Composable \u2192 Exporters, Prometheus, Grafana, and Alertmanager each serve a focused role.</li> <li>Kubernetes-Native \u2192 Uses service discovery, ConfigMaps, and the Prometheus Operator for automation.</li> <li>Automation-First \u2192 Deployed and managed via Helm charts, Operators, and GitOps pipelines.</li> <li>Production-Ready \u2192 High-availability Prometheus, RBAC-enabled, and scalable with Thanos/Cortex.</li> <li>Developer-Friendly \u2192 Can be run locally with Kind or Minikube for experimentation.</li> </ul>"},{"location":"1-architecture/0-overview/#core-components","title":"Core Components","text":""},{"location":"1-architecture/0-overview/#1-metrics-collection-exporters-kube-state-metrics","title":"1. Metrics Collection (Exporters &amp; Kube-State-Metrics)","text":"<ul> <li>kubelet / cAdvisor \u2192 Collects container and pod-level resource usage (CPU, memory, disk, network).</li> <li>kube-state-metrics \u2192 Exposes the state of Kubernetes objects (deployments, pods, nodes, jobs).</li> <li>Node Exporter \u2192 Provides node-level OS metrics.</li> <li>All expose metrics at <code>/metrics</code> in Prometheus format.</li> </ul>"},{"location":"1-architecture/0-overview/#2-monitoring-storage-prometheus-prometheus-operator","title":"2. Monitoring &amp; Storage (Prometheus / Prometheus Operator)","text":"<ul> <li>Prometheus scrapes metrics automatically via Kubernetes service discovery.</li> <li>Stores data in a time-series database (TSDB).</li> <li>Prometheus Operator manages Prometheus, Alertmanager, and scrape configurations declaratively with CRDs (<code>ServiceMonitor</code>, <code>PodMonitor</code>, <code>PrometheusRule</code>).</li> <li>PromQL enables deep querying of cluster and application metrics.</li> </ul>"},{"location":"1-architecture/0-overview/#3-visualization-grafana","title":"3. Visualization (Grafana)","text":"<ul> <li>Grafana connects to Prometheus and provides pre-built dashboards for Kubernetes clusters, nodes, pods, and workloads.</li> <li>Developers and SREs can explore, visualize, and share insights from cluster metrics.</li> </ul>"},{"location":"1-architecture/0-overview/#4-alerting-alertmanager","title":"4. Alerting (Alertmanager)","text":"<ul> <li>Alertmanager receives alerts from Prometheus.</li> <li>Handles deduplication, grouping, and routing of alerts.</li> <li>Sends notifications via Slack, Email, PagerDuty, or other integrations.</li> <li>Rules are defined in PrometheusRule CRDs for Kubernetes-native configuration.</li> </ul>"},{"location":"1-architecture/0-overview/#kubernetes-monitoring-architecture-diagram","title":"Kubernetes Monitoring Architecture Diagram","text":"<pre><code>flowchart TD\n\n    subgraph Node[\"Kubernetes Node\"]\n        subgraph Pods[\"Pods &amp; Containers\"]\n            A1[\"App Pod A\"]\n            A2[\"App Pod B\"]\n        end\n        C[\"kubelet / cAdvisor\"]\n        N[\"Node Exporter\"]\n    end\n\n    KS[\"kube-state-metrics\"]\n\n    A1 --&gt; C\n    A2 --&gt; C\n    N --&gt; P[\"Prometheus (via Operator)\"]\n    C --&gt; P\n    KS --&gt; P\n\n    P --&gt; G[\"Grafana Dashboards\"]\n    P --&gt; A[\"Alertmanager\"]\n\n    G --&gt; U[\"User (SRE/DevOps)\"]\n    A --&gt; U</code></pre>"},{"location":"1-architecture/0-overview/#data-control-flow","title":"Data / Control Flow","text":"<ol> <li>Pods and nodes run applications and workloads.</li> <li>kubelet/cAdvisor collect container and pod-level metrics.</li> <li>kube-state-metrics exposes cluster object states (deployments, pods, jobs, etc.).</li> <li>Node Exporter collects host-level metrics (CPU, memory, disk).</li> <li>Prometheus scrapes all metrics via Kubernetes service discovery.</li> <li>TSDB stores the metrics for querying.</li> <li>Grafana queries Prometheus and renders dashboards.</li> <li>Prometheus Rules (via CRDs) define alert conditions.</li> <li>Alertmanager routes alerts to notification channels.</li> <li>Users (SRE/DevOps) observe dashboards and respond to incidents.</li> </ol>"},{"location":"1-architecture/0-overview/#related-pages","title":"Related Pages","text":"<ul> <li>Quickstart: Getting Started</li> <li>Prometheus Notes</li> <li>Grafana Notes</li> <li>Alertmanager Notes</li> </ul>"},{"location":"2-project/alertmanager/","title":"What is Alertmanager?","text":"<p>Alertmanager is the alerting component of the Prometheus ecosystem. It is responsible for handling alerts generated by Prometheus servers and sending notifications to external systems.</p> <p>It provides:</p> <ul> <li>Routing \u2192 decide where alerts go (Slack, Email, PagerDuty, etc.)</li> <li>Grouping \u2192 combine related alerts into a single notification</li> <li>Silencing \u2192 temporarily mute alerts during maintenance</li> <li>Deduplication \u2192 avoid spamming users with repeated alerts</li> </ul> <p>Prometheus detects the problem, but Alertmanager tells humans (or systems) about it.</p>"},{"location":"2-project/alertmanager/#why-do-we-need-alertmanager","title":"Why Do We Need Alertmanager?","text":"<p>Without Alertmanager:</p> <ul> <li>Prometheus can trigger alerts, but it doesn\u2019t know how to notify people.</li> <li>Each alert would generate raw, unorganised messages.</li> </ul> <p>Challenges Alertmanager solves:</p> <ul> <li>Too many alerts \u2192 group and deduplicate.</li> <li>Wrong people notified \u2192 route to the right team.</li> <li>Alert fatigue \u2192 silence during maintenance.</li> </ul> <p>It\u2019s the traffic controller for alerts.</p>"},{"location":"2-project/alertmanager/#how-alertmanager-works","title":"How Alertmanager Works","text":"<ol> <li> <p>Prometheus evaluates alert rules (<code>.rules</code> or <code>.yml</code> files).</p> </li> <li> <p>If a rule fires, Prometheus sends an alert to Alertmanager via HTTP.</p> </li> <li> <p>Alertmanager:</p> </li> <li> <p>Groups related alerts.</p> </li> <li>Applies routing rules (e.g., critical \u2192 PagerDuty, warnings \u2192 Slack).</li> <li> <p>Sends notifications.</p> </li> <li> <p>Users acknowledge alerts, silence them if needed, or take action.</p> </li> </ol>"},{"location":"2-project/alertmanager/#architecture-overview","title":"Architecture Overview","text":"<pre><code>+-+\n| Prometheus Server |  --&gt;  Fires alerts\n+++\n          |\n          v\n+++\n| Alertmanager      |\n| - Grouping        |\n| - Routing         |\n| - Silencing       |\n| - Deduplication   |\n+++\n   |   |   |   |\n   v   v   v   v\n Email Slack PagerDuty Webhook\n</code></pre>"},{"location":"2-project/alertmanager/#alert-flow-from-prometheus-alertmanager-user","title":"Alert Flow: From Prometheus \u2192 Alertmanager \u2192 User","text":"<pre><code>sequenceDiagram\n    participant Prom as Prometheus\n    participant AM as Alertmanager\n    participant User as User (SRE/DevOps)\n\n    Prom-&gt;&gt;AM: Send alert (HTTP POST)\n    AM-&gt;&gt;AM: Group, Deduplicate, Silence\n    AM-&gt;&gt;User: Send notification (Slack/Email/PagerDuty)\n    User-&gt;&gt;AM: Silence/Ack alert (optional)</code></pre>"},{"location":"2-project/alertmanager/#example-alert-rule-in-prometheus","title":"Example Alert Rule in Prometheus","text":"<pre><code>groups:\n  - name: node.rules\n    rules:\n      - alert: HighCPUUsage\n        expr: rate(node_cpu_seconds_total{mode=\"user\"}[1m]) &gt; 0.9\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High CPU usage on {{ $labels.instance }}\"\n          description: \"CPU usage &gt; 90% for more than 2 minutes.\"\n</code></pre> <p>When this condition is true, Prometheus sends an alert to Alertmanager.</p>"},{"location":"2-project/alertmanager/#alertmanager-configuration","title":"Alertmanager Configuration","text":"<p>Alertmanager is configured using a YAML file (<code>alertmanager.yml</code>).</p>"},{"location":"2-project/alertmanager/#example-config","title":"Example Config","text":"<pre><code>global:\n  resolve_timeout: 5m\n\nroute:\n  receiver: 'slack-notifications'\n  group_by: ['alertname', 'cluster']\n  group_wait: 30s\n  group_interval: 5m\n  repeat_interval: 3h\n\nreceivers:\n  - name: 'slack-notifications'\n    slack_configs:\n      - channel: '#alerts'\n        send_resolved: true\n        text: \"Alert: {{ .CommonAnnotations.summary }}\"\n\ninhibit_rules:\n  - source_match:\n      severity: 'critical'\n    target_match:\n      severity: 'warning'\n    equal: ['alertname', 'cluster']\n</code></pre>"},{"location":"2-project/alertmanager/#explanation-of-key-fields","title":"Explanation of Key Fields","text":"<ul> <li>global \u2192 default settings (timeouts, SMTP server, Slack API URL).</li> <li> <p>route \u2192 defines alert routing rules.</p> </li> <li> <p><code>group_by</code> \u2192 group alerts by label.</p> </li> <li><code>group_wait</code> \u2192 wait before sending to group alerts.</li> <li><code>repeat_interval</code> \u2192 resend alert if still firing.</li> <li>receivers \u2192 list of destinations (Slack, email, PagerDuty).</li> <li>inhibit_rules \u2192 suppress lower-priority alerts if a higher one is firing.</li> </ul>"},{"location":"2-project/alertmanager/#notification-integrations","title":"Notification Integrations","text":"<p>Alertmanager supports many integrations out of the box:</p> <ul> <li>Email</li> <li>Slack, Microsoft Teams, Discord</li> <li>PagerDuty, OpsGenie, VictorOps</li> <li>Webhook receivers \u2192 integrate with any custom system</li> <li>Custom receivers via webhooks</li> </ul>"},{"location":"2-project/alertmanager/#features-of-alertmanager","title":"Features of Alertmanager","text":""},{"location":"2-project/alertmanager/#grouping","title":"Grouping","text":"<ul> <li>Combine alerts into a single message.</li> <li>Example: instead of 100 pod alerts, one grouped \u201cPodCrashLoopBackOff\u201d alert.</li> </ul>"},{"location":"2-project/alertmanager/#routing","title":"Routing","text":"<ul> <li>Send alerts to different teams.</li> <li>Example: Database alerts \u2192 DBA team, Node alerts \u2192 Infra team.</li> </ul>"},{"location":"2-project/alertmanager/#deduplication","title":"Deduplication","text":"<ul> <li>If an alert is firing repeatedly, only send once until it\u2019s resolved.</li> </ul>"},{"location":"2-project/alertmanager/#silences","title":"Silences","text":"<ul> <li>Mute alerts temporarily (e.g., during maintenance).</li> <li>Configured via API/UI/CLI.</li> </ul>"},{"location":"2-project/alertmanager/#inhibition","title":"Inhibition","text":"<ul> <li>Suppress less severe alerts when a higher severity alert is active.</li> <li>Example: Hide \u201cdisk usage warning\u201d if \u201cdisk full critical\u201d is active.</li> </ul>"},{"location":"2-project/alertmanager/#alertmanager-ui","title":"Alertmanager UI","text":"<p>Alertmanager provides a simple web UI (default port <code>:9093</code>) where you can:</p> <ul> <li>View active alerts</li> <li>Add silences</li> <li>Manage alert history</li> <li>Debug routing</li> </ul>"},{"location":"2-project/alertmanager/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Don\u2019t expose Alertmanager directly to the internet.</li> <li>Put it behind a reverse proxy (Nginx/Traefik).</li> <li>Use authentication if exposed.</li> <li>Secure communication between Prometheus and Alertmanager with TLS.</li> </ul>"},{"location":"2-project/alertmanager/#key-strengths-of-alertmanager","title":"Key Strengths of Alertmanager","text":"<ul> <li>Deep Prometheus integration \u2192 native in the ecosystem.</li> <li>Powerful routing \u2192 fine-grained alert delivery.</li> <li>Extensible \u2192 webhooks for custom workflows.</li> <li>Silences &amp; inhibition \u2192 reduce noise &amp; alert fatigue.</li> <li>Open-source &amp; widely adopted \u2192 large community.</li> </ul>"},{"location":"2-project/alertmanager/#limitations-watch-outs","title":"Limitations &amp; Watch Outs","text":"<ul> <li>Limited UI (mostly config-driven).</li> <li>No built-in escalation policies (PagerDuty is better for escalation chains).</li> <li>Single binary \u2192 HA requires running multiple instances with a gossip protocol.</li> <li>Alert storming still possible if rules aren\u2019t well-tuned.</li> </ul>"},{"location":"2-project/alertmanager/#alertmanager-in-the-observability-stack","title":"Alertmanager in the Observability Stack","text":"<pre><code>flowchart TD\n\n    subgraph Metrics\n        P[Prometheus]\n    end\n\n    subgraph Alerting\n        A[Alertmanager]\n    end\n\n    subgraph Notifications\n        E[Email]\n        S[Slack]\n        PD[PagerDuty]\n        W[Webhook]\n    end\n\n    P --&gt; A\n    A --&gt; E\n    A --&gt; S\n    A --&gt; PD\n    A --&gt; W</code></pre> <p>Prometheus detects, Alertmanager notifies.</p>"},{"location":"2-project/alertmanager/#alertmanager-cheat-sheet","title":"Alertmanager Cheat Sheet","text":""},{"location":"2-project/alertmanager/#core-concepts","title":"Core Concepts","text":"Term Meaning Alert Condition defined in Prometheus that triggers Receiver Where alerts are sent (Slack, Email, etc.) Route Rules that decide which receiver gets the alert Silence Temporary mute for alerts Inhibition Suppression of lower alerts when higher ones fire Grouping Bundling multiple alerts into one notification"},{"location":"2-project/alertmanager/#example-silence-command","title":"Example Silence Command","text":"<pre><code>amtool silence add alertname=HighCPUUsage --duration=2h --comment=\"Maintenance window\"\n</code></pre>"},{"location":"2-project/alertmanager/#example-routing-rule","title":"Example Routing Rule","text":"<pre><code>route:\n  receiver: 'team-A'\n  routes:\n    - match:\n        team: 'database'\n      receiver: 'dba-team'\n    - match:\n        team: 'infra'\n      receiver: 'infra-team'\n</code></pre>"},{"location":"2-project/alertmanager/#final-takeaway","title":"Final Takeaway","text":"<p>Alertmanager is:</p> <ul> <li>The alert distribution hub for Prometheus.</li> <li>Provides routing, grouping, silencing, inhibition.</li> <li>Supports many integrations (Slack, PagerDuty, Email).</li> <li>Essential for production-grade monitoring.</li> </ul> <p>Think of Prometheus as the doctor detecting the illness, and Alertmanager as the nurse paging the right specialist.</p>"},{"location":"2-project/cadvisor/","title":"cAdvisor","text":""},{"location":"2-project/cadvisor/#what-is-cadvisor","title":"What is cAdvisor?","text":"<p>cAdvisor (Container Advisor) is an open-source container monitoring tool developed by Google. It runs as a daemon on a host and provides insights into:</p> <ul> <li>Resource usage (CPU, memory, network, disk I/O)</li> <li>Performance characteristics of running containers</li> <li>Per-container statistics in real time</li> </ul> <p>cAdvisor is often used as a metrics source for Prometheus in Kubernetes and Docker environments.</p> <p>It\u2019s lightweight, designed to run inside a container, and exposes metrics at an HTTP endpoint (<code>/metrics</code>) in Prometheus format.</p>"},{"location":"2-project/cadvisor/#why-do-we-need-cadvisor","title":"Why Do We Need cAdvisor?","text":"<p>In modern containerised environments (Docker, Kubernetes):</p> <ul> <li>Containers are ephemeral (come and go quickly).</li> <li>Multiple containers share the same host.</li> <li>We need visibility into resource consumption per container (not just at the host level).</li> </ul> <p>Without cAdvisor:</p> <ul> <li>You can see host metrics (via <code>node_exporter</code>) but not per-container usage.</li> <li>Hard to debug issues like \u201cwhich container is consuming all the CPU?\u201d</li> </ul> <p>cAdvisor provides fine-grained container-level metrics, making it critical for container monitoring.</p>"},{"location":"2-project/cadvisor/#what-does-cadvisor-monitor","title":"What Does cAdvisor Monitor?","text":"<p>cAdvisor collects and exposes:</p> <ul> <li>CPU usage (total, per core, throttling).</li> <li>Memory usage (working set, cache, limits).</li> <li>Filesystem usage (per container).</li> <li>Network stats (bytes sent/received, packets).</li> <li>Container lifecycle stats (start, stop, restart).</li> <li>Custom labels (Kubernetes adds pod, namespace, container name).</li> </ul>"},{"location":"2-project/cadvisor/#how-cadvisor-works","title":"How cAdvisor Works","text":"<ol> <li>Runs as a daemon (usually a Docker container).</li> <li>Reads metrics from the Linux kernel cgroups and container runtime (Docker, containerd, CRI-O).</li> <li> <p>Exposes metrics on an HTTP endpoint:</p> </li> <li> <p>JSON API \u2192 <code>/api/v1.3/subcontainers</code> (legacy).</p> </li> <li>Prometheus format \u2192 <code>/metrics</code>.</li> <li>Tools like Prometheus scrape these metrics.</li> <li>Grafana visualises them in dashboards.</li> </ol>"},{"location":"2-project/cadvisor/#architecture-overview","title":"Architecture Overview","text":"<pre><code>+-+\n|   Linux Kernel    |\n| (cgroups, stats)  |\n+++\n          |\n          v\n+++\n|   cAdvisor        |  (container metrics daemon)\n+++\n          |\n          v\n+-+\n| /metrics endpoint |  --&gt; Scraped by Prometheus\n+++\n          |\n     +-v--+\n     | Grafana  |   (visualisation)\n     +-+\n</code></pre>"},{"location":"2-project/cadvisor/#metric-flow-from-container-cadvisor-prometheus-grafana","title":"Metric Flow: From Container \u2192 cAdvisor \u2192 Prometheus \u2192 Grafana","text":"<pre><code>sequenceDiagram\n    participant Cont as Container\n    participant Kernel as Linux cgroups\n    participant Cad as cAdvisor (/metrics)\n    participant Prom as Prometheus\n    participant Graf as Grafana\n    participant User as DevOps/SRE\n\n    Cont-&gt;&gt;Kernel: Resource usage (CPU, mem, I/O)\n    Cad-&gt;&gt;Kernel: Collect stats via cgroups\n    Prom-&gt;&gt;Cad: Scrape /metrics\n    Prom-&gt;&gt;Prom: Store in TSDB\n    Graf-&gt;&gt;Prom: Query metrics\n    Prom--&gt;&gt;Graf: Return data\n    Graf--&gt;&gt;User: Show dashboards</code></pre>"},{"location":"2-project/cadvisor/#prometheus-cadvisor-architecture","title":"Prometheus + cAdvisor Architecture","text":"<pre><code>flowchart TD\n\n    subgraph Containers[\"Running Containers (Docker/K8s)\"]\n        C1[\"Container A\"]\n        C2[\"Container B\"]\n        C3[\"Container C\"]\n    end\n\n    subgraph Kernel[\"Linux Kernel (cgroups, namespaces)\"]\n        M1[\"CPU usage\"]\n        M2[\"Memory usage\"]\n        M3[\"Disk I/O\"]\n        M4[\"Network I/O\"]\n    end\n\n    Containers --&gt; Kernel\n\n    subgraph cAdvisor[\"cAdvisor Daemon (per-node)\"]\n        Cad[\"/metrics endpoint\"]\n    end\n\n    Kernel --&gt; Cad\n\n    subgraph Prometheus[\"Prometheus Server\"]\n        P[\"Scrape &amp; Store Metrics (TSDB)\"]\n    end\n\n    Cad --&gt; P\n\n    subgraph Grafana[\"Grafana Dashboards\"]\n        G[\"Visualise Metrics\"]\n    end\n\n    Prometheus --&gt; G\n\n    subgraph Alertmanager[\"Alertmanager\"]\n        A[\"Send Alerts (Slack, Email, PagerDuty)\"]\n    end\n\n    Prometheus --&gt; A</code></pre>"},{"location":"2-project/cadvisor/#explanation-of-the-flow","title":"Explanation of the Flow","text":"<ol> <li>Containers \u2192 generate resource usage.</li> <li>Linux Kernel (cgroups) \u2192 tracks CPU, memory, disk, and network per container.</li> <li>cAdvisor \u2192 collects these stats and exposes them at <code>/metrics</code>.</li> <li>Prometheus \u2192 scrapes cAdvisor metrics regularly and stores them in its TSDB.</li> <li>Grafana \u2192 queries Prometheus for dashboards (per-container CPU/memory, etc.).</li> <li>Alertmanager \u2192 triggers alerts if rules match (e.g., container using &gt;90% memory).</li> </ol> <p>This stack gives complete visibility into container performance.</p>"},{"location":"2-project/cadvisor/#kubernetes-cadvisor-prometheus-architecture","title":"Kubernetes + cAdvisor + Prometheus Architecture","text":"<pre><code>flowchart TD\n\n    subgraph Node[\"Kubernetes Node\"]\n        subgraph Pods[\"Pods &amp; Containers\"]\n            P1[\"Pod A: Container A1, A2\"]\n            P2[\"Pod B: Container B1\"]\n        end\n\n        subgraph Kubelet[\"Kubelet\"]\n            Cad[\"cAdvisor (built-in)\"]\n        end\n\n        Kernel[\"Linux Kernel (cgroups, namespaces)\"]\n    end\n\n    Pods --&gt; Kernel\n    Kernel --&gt; Cad\n\n    subgraph Prometheus[\"Prometheus Server\"]\n        P[\"Scrape &amp; Store Metrics\"]\n    end\n\n    Cad --&gt; P\n\n    subgraph Grafana[\"Grafana Dashboards\"]\n        G[\"Visualise Metrics\"]\n    end\n\n    Prometheus --&gt; G\n\n    subgraph Alertmanager[\"Alertmanager\"]\n        A[\"Send Alerts (Slack, Email, PagerDuty)\"]\n    end\n\n    Prometheus --&gt; A</code></pre>"},{"location":"2-project/cadvisor/#explanation-of-the-kubernetes-flow","title":"Explanation of the Kubernetes Flow","text":"<ol> <li>Pods (containers) run on each node.</li> <li>Linux kernel (cgroups) tracks per-container resource usage (CPU, memory, I/O).</li> <li> <p>Kubelet runs on every node and integrates cAdvisor internally.</p> </li> <li> <p>Exposes metrics at:</p> <ul> <li><code>/metrics/cadvisor</code> \u2192 container-level</li> <li><code>/metrics</code> \u2192 node &amp; kubelet metrics</li> <li>Prometheus scrapes kubelet endpoints across all nodes.</li> <li>Grafana builds dashboards (per-pod, per-container, per-namespace).</li> <li>Alertmanager notifies when resource thresholds are breached.</li> </ul> </li> </ol> <p>In Kubernetes, you don\u2019t usually run standalone cAdvisor. Instead, kubelet already provides cAdvisor-powered metrics.</p>"},{"location":"2-project/cadvisor/#example-metrics-from-cadvisor","title":"Example Metrics from cAdvisor","text":""},{"location":"2-project/cadvisor/#cpu","title":"CPU","text":"<ul> <li><code>container_cpu_usage_seconds_total</code> \u2192 Total CPU time consumed.</li> <li><code>container_cpu_cfs_throttled_seconds_total</code> \u2192 Time container spent throttled.</li> </ul>"},{"location":"2-project/cadvisor/#memory","title":"Memory","text":"<ul> <li><code>container_memory_usage_bytes</code> \u2192 Total memory usage.</li> <li><code>container_memory_working_set_bytes</code> \u2192 Memory actively used.</li> </ul>"},{"location":"2-project/cadvisor/#network","title":"Network","text":"<ul> <li><code>container_network_receive_bytes_total</code></li> <li><code>container_network_transmit_bytes_total</code></li> </ul>"},{"location":"2-project/cadvisor/#filesystem","title":"Filesystem","text":"<ul> <li><code>container_fs_usage_bytes</code></li> <li><code>container_fs_reads_bytes_total</code></li> </ul>"},{"location":"2-project/cadvisor/#running-cadvisor","title":"Running cAdvisor","text":""},{"location":"2-project/cadvisor/#docker-example","title":"Docker Example","text":"<pre><code>docker run \\\n  --volume=/:/rootfs:ro \\\n  --volume=/var/run:/var/run:rw \\\n  --volume=/sys:/sys:ro \\\n  --volume=/var/lib/docker/:/var/lib/docker:ro \\\n  --publish=8080:8080 \\\n  --detach=true \\\n  --name=cadvisor \\\n  gcr.io/cadvisor/cadvisor:latest\n</code></pre> <p>Access metrics at:</p> <ul> <li>UI: <code>http://localhost:8080</code></li> <li>Prometheus metrics: <code>http://localhost:8080/metrics</code></li> </ul>"},{"location":"2-project/cadvisor/#cadvisor-in-kubernetes","title":"cAdvisor in Kubernetes","text":"<p>In Kubernetes, cAdvisor is built into the kubelet:</p> <ul> <li>Every node\u2019s kubelet runs cAdvisor.</li> <li>Metrics are exposed at <code>:4194/metrics/cadvisor</code>.</li> <li>Prometheus scrapes these endpoints.</li> </ul> <p>Many Kubernetes setups use kubelet\u2019s cAdvisor integration rather than running cAdvisor as a separate container.</p>"},{"location":"2-project/cadvisor/#key-strengths-of-cadvisor","title":"Key Strengths of cAdvisor","text":"<ul> <li>Container-native: built specifically for container monitoring.</li> <li>Lightweight: low resource overhead.</li> <li>Rich metrics: CPU, memory, disk, network at per-container level.</li> <li>Easy integration: works out-of-the-box with Prometheus.</li> <li>UI dashboard: basic real-time web UI included.</li> </ul>"},{"location":"2-project/cadvisor/#limitations-watch-outs","title":"Limitations &amp; Watch Outs","text":"<ul> <li> <p>Short-term storage only \u2192 cAdvisor itself doesn\u2019t persist data (only in-memory).   \u2192 Must use Prometheus or other TSDB for historical metrics.</p> </li> <li> <p>Scalability \u2192 Standalone cAdvisor isn\u2019t meant for very large clusters.</p> </li> <li> <p>Limited security \u2192 Exposes metrics unauthenticated (protect behind reverse proxy).</p> </li> <li> <p>Deprecation concern \u2192 Standalone cAdvisor development has slowed since metrics are now integrated into Kubernetes kubelet.</p> </li> </ul>"},{"location":"2-project/cadvisor/#example-prometheus-scrape-config-for-cadvisor","title":"Example Prometheus Scrape Config for cAdvisor","text":"<pre><code>scrape_configs:\n  - job_name: 'cadvisor'\n    static_configs:\n      - targets: ['localhost:8080']\n</code></pre>"},{"location":"2-project/cadvisor/#grafana-dashboards-for-cadvisor","title":"Grafana Dashboards for cAdvisor","text":"<p>Grafana has many pre-built dashboards (via Grafana.com) for cAdvisor metrics:</p> <ul> <li>Container CPU &amp; memory usage</li> <li>Disk &amp; network performance</li> <li>Top N containers by resource consumption</li> <li>Per-pod or per-namespace breakdown</li> </ul> <p>Example dashboard ID: 893 (Google cAdvisor).</p>"},{"location":"2-project/cadvisor/#alternatives-to-cadvisor","title":"Alternatives to cAdvisor","text":"Tool Focus Notes node_exporter Host-level metrics No per-container visibility kubelet /metrics Node &amp; pod metrics in k8s Already includes cAdvisor functionality Docker stats API Docker container metrics Limited, less Prometheus-friendly Datadog/ELK/others SaaS full observability stacks More features, but paid solutions <p>In Kubernetes, cAdvisor + kubelet is usually enough.</p>"},{"location":"2-project/cadvisor/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Don\u2019t expose cAdvisor directly to the internet.</li> <li>Run behind a reverse proxy (Nginx, Traefik).</li> <li>Scrape metrics only from trusted networks.</li> <li>Use Kubernetes RBAC with kubelet metrics proxying.</li> </ul>"},{"location":"2-project/cadvisor/#cadvisor-cheat-sheet","title":"cAdvisor Cheat Sheet","text":""},{"location":"2-project/cadvisor/#core-concepts","title":"Core Concepts","text":"Term Meaning cAdvisor Container metrics daemon (by Google) Source Linux kernel cgroups + container runtime Metrics CPU, memory, disk, network per container Endpoint <code>/metrics</code> (Prometheus format)"},{"location":"2-project/cadvisor/#example-promql","title":"Example PromQL","text":"<pre><code>rate(container_cpu_usage_seconds_total[1m])   # CPU usage per second\ncontainer_memory_usage_bytes                  # Current memory usage\ncontainer_network_receive_bytes_total         # Network RX bytes\n</code></pre>"},{"location":"2-project/cadvisor/#final-takeaway","title":"Final Takeaway","text":"<p>cAdvisor is:</p> <ul> <li>Essential for per-container resource monitoring.</li> <li>Lightweight and easy to deploy.</li> <li>Integrated into Kubernetes via kubelet.</li> <li>Best used with Prometheus + Grafana for long-term monitoring.</li> </ul> <p>Think of cAdvisor as the container-level metrics engine that feeds Prometheus, while node_exporter gives you host-level metrics.</p>"},{"location":"2-project/grafana/","title":"Grafana","text":""},{"location":"2-project/grafana/#what-is-grafana","title":"What is Grafana?","text":"<p>Grafana is an open-source observability and visualization platform. It lets you query, visualise, alert, and explore metrics, logs, and traces from multiple data sources.</p> <p>Originally created by Torkel \u00d6degaard, Grafana has grown into a CNCF incubating project and is now the de facto dashboarding tool in cloud-native monitoring stacks.</p> <p>If Prometheus is the \u201cbrain\u201d of monitoring (data collection &amp; querying), Grafana is the eyes (dashboards &amp; visualisations).</p>"},{"location":"2-project/grafana/#why-do-we-need-grafana","title":"Why Do We Need Grafana?","text":"<p>Modern systems generate huge amounts of telemetry data:</p> <ul> <li>Metrics (from Prometheus, InfluxDB, Graphite, etc.)</li> <li>Logs (from Loki, Elasticsearch, Splunk, etc.)</li> <li>Traces (from Jaeger, Tempo, Zipkin, etc.)</li> </ul> <p>Without visualisation, raw metrics are hard to interpret. Grafana solves this by:</p> <ul> <li>Turning metrics into interactive dashboards</li> <li>Providing alerting when thresholds are crossed</li> <li>Enabling multi-source observability (metrics + logs + traces in one UI)</li> </ul> <p>Grafana = single pane of glass for observability.</p>"},{"location":"2-project/grafana/#how-grafana-works","title":"How Grafana Works","text":"<p>Grafana itself does not collect data. Instead, it:</p> <ol> <li>Connects to data sources (Prometheus, Loki, Elasticsearch, etc.)</li> <li>Executes queries against them</li> <li>Renders results in panels (graphs, gauges, tables, heatmaps, etc.)</li> <li>Organises panels into dashboards</li> <li>Provides alerting &amp; notifications based on panel queries</li> </ol>"},{"location":"2-project/grafana/#architecture-overview","title":"Architecture Overview","text":"<pre><code>++\n| Data Sources     |   (Prometheus, Loki, Tempo, etc.)\n++--+\n          |\n          v\n+++\n|  Grafana Server   |\n|  - Query engine   |\n|  - Panels         |\n|  - Alerting       |\n+++\n          |\n   +++  \n   | Dashboards |  \n   +++  \n          |\n      End Users\n</code></pre>"},{"location":"2-project/grafana/#data-flow-from-metrics-grafana-user","title":"Data Flow: From Metrics \u2192 Grafana \u2192 User","text":"<pre><code>sequenceDiagram\n    participant DS as Data Source (Prometheus, Loki, etc.)\n    participant G as Grafana\n    participant User as User (SRE/DevOps)\n\n    User-&gt;&gt;G: Request dashboard\n    G-&gt;&gt;DS: Query metrics/logs/traces\n    DS--&gt;&gt;G: Return results\n    G--&gt;&gt;User: Render panels\n    G-&gt;&gt;User: Send alerts (if configured)</code></pre>"},{"location":"2-project/grafana/#example-grafana-panels","title":"Example Grafana Panels","text":"<p>Grafana supports many visualisation types:</p> <ul> <li>Time series graph \u2192 CPU usage over time</li> <li>Gauge / SingleStat \u2192 current memory usage</li> <li>Heatmap \u2192 latency distribution</li> <li>Table \u2192 list of failing pods</li> <li>Pie chart \u2192 % of requests per region</li> </ul> <p>Panels can be grouped into dashboards (e.g., \u201cKubernetes Cluster Health\u201d).</p>"},{"location":"2-project/grafana/#common-data-sources","title":"Common Data Sources","text":"<p>Grafana supports dozens of backends. Most common:</p> Type Example Purpose Metrics Prometheus, InfluxDB, Graphite Time-series metrics Logs Loki, Elasticsearch, Splunk Centralised logging Traces Tempo, Jaeger, Zipkin Distributed tracing Databases MySQL, PostgreSQL Custom queries Cloud AWS CloudWatch, GCP Monitoring, Azure Monitor Cloud-native monitoring <p>Grafana turns it into a multi-source observability platform.</p>"},{"location":"2-project/grafana/#alerting-in-grafana","title":"Alerting in Grafana","text":"<p>Grafana provides a unified alerting system (since v8):</p> <ul> <li>Create alerts directly from panels.</li> <li>Alerts are evaluated on the Grafana server.</li> <li> <p>Notifications are sent via channels:</p> </li> <li> <p>Slack</p> </li> <li>Email</li> <li>PagerDuty</li> <li>Microsoft Teams</li> <li>Webhooks</li> </ul>"},{"location":"2-project/grafana/#example-alert-flow","title":"Example Alert Flow","text":"<ol> <li>Define a threshold (e.g., CPU usage &gt; 80%).</li> <li>Grafana runs the query periodically.</li> <li>If condition matches, an alert fires.</li> <li>Notification goes to configured channel.</li> </ol>"},{"location":"2-project/grafana/#installing-grafana","title":"Installing Grafana","text":""},{"location":"2-project/grafana/#docker","title":"Docker","text":"<pre><code>docker run -d -p 3000:3000 grafana/grafana\n</code></pre> <ul> <li>UI: <code>http://localhost:3000</code></li> <li>Default credentials: <code>admin/admin</code></li> </ul>"},{"location":"2-project/grafana/#kubernetes-helm","title":"Kubernetes (Helm)","text":"<pre><code>helm repo add grafana https://grafana.github.io/helm-charts\nhelm install grafana grafana/grafana\n</code></pre>"},{"location":"2-project/grafana/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Always set admin password (default is insecure).</li> <li>Enable TLS if exposed publicly.</li> <li>Use OAuth/SAML/LDAP for authentication.</li> <li>Use folders &amp; permissions to restrict dashboard access.</li> <li>Enable audit logs for compliance.</li> </ul>"},{"location":"2-project/grafana/#key-strengths-of-grafana","title":"Key Strengths of Grafana","text":"<ul> <li>Multi-data-source (metrics, logs, traces, SQL, cloud).</li> <li>Rich visualisations (100+ panel types, plugins).</li> <li>Pre-built dashboards (Grafana.com library).</li> <li>Fast querying &amp; exploration (great with Prometheus).</li> <li>Unified alerting with many integrations.</li> <li>Extensible (plugins for panels, datasources, apps).</li> </ul>"},{"location":"2-project/grafana/#limitations-watch-outs","title":"Limitations &amp; Watch Outs","text":"<ul> <li>No storage \u2192 relies on external data sources.</li> <li>Query-heavy dashboards \u2192 can overload Prometheus/DB.</li> <li>High availability setup requires external DB (MySQL/Postgres).</li> <li>User management is limited in OSS (Grafana Enterprise adds RBAC, reporting).</li> </ul>"},{"location":"2-project/grafana/#grafana-in-the-observability-stack","title":"Grafana in the Observability Stack","text":"<pre><code>flowchart TD\n\n    subgraph Metrics\n        P[Prometheus]\n        N[node_exporter]\n        C[cAdvisor]\n    end\n\n    subgraph Logs\n        L[Loki]\n    end\n\n    subgraph Traces\n        T[Tempo]\n    end\n\n    subgraph Grafana[\"Grafana Dashboards\"]\n        G[\"Dashboards + Alerts\"]\n    end\n\n    P --&gt; G\n    L --&gt; G\n    T --&gt; G</code></pre> <p>Grafana = central observability frontend for metrics, logs, and traces.</p>"},{"location":"2-project/grafana/#grafana-cheat-sheet","title":"Grafana Cheat Sheet","text":""},{"location":"2-project/grafana/#core-concepts","title":"Core Concepts","text":"Term Meaning Data source External system providing data (Prometheus, Loki, etc.) Panel Single visualisation (graph, table, etc.) Dashboard Collection of panels Alert Rule based on a query, triggers notification Organisation Multi-tenant separation in Grafana Folder Logical grouping of dashboards"},{"location":"2-project/grafana/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>System monitoring (CPU, memory, disk usage).</li> <li>Kubernetes monitoring (pods, nodes, namespaces).</li> <li>Business metrics (orders per minute, revenue trends).</li> <li>Application performance monitoring (APM).</li> <li>Log exploration (with Loki/Elasticsearch).</li> </ul>"},{"location":"2-project/grafana/#final-takeaway","title":"Final Takeaway","text":"<p>Grafana is:</p> <ul> <li>The visualisation + alerting layer of modern monitoring stacks.</li> <li>Datasource-agnostic (works with metrics, logs, traces, SQL).</li> <li>Essential for Kubernetes, microservices, and cloud-native setups.</li> </ul> <p>Think of Grafana as the dashboard and control room where DevOps, SREs, and engineers get their insights.</p>"},{"location":"2-project/helm/","title":"What is Helm?","text":"<p>Info</p> <p>During  <code>helm install</code>, it's important to always state the version of helm chart that you are using by making use of the <code>--version</code> flag. A repeatable way is to use a tool like <code>Terraform</code></p> <p>These are the current versions of the charts we used in this tutorial:</p> <pre><code>NAME           CHART                            APP VERSION\nloki           loki-6.41.1                      3.5.5\nprometheus     kube-prometheus-stack-77.11.1    v0.85.0\n</code></pre> <p>Helm is the package manager for Kubernetes. It manages charts, which are preconfigured collections of Kubernetes manifests.</p> <p>Charts bundle deployments, services, config maps, secrets, ingress rules, and more into a single, reusable unit.</p> <p>Helm makes installing, upgrading, rolling back, and managing complex Kubernetes apps predictable and repeatable.</p>"},{"location":"2-project/helm/#why-use-helm","title":"Why Use Helm?","text":"<p>Kubernetes manifests are verbose and repetitive. Managing large apps by hand is error-prone. Helm provides:</p> <ul> <li>Templating: DRY YAML with variables and conditionals.</li> <li>Versioning: Rollback to earlier states easily.</li> <li>Releases: Track each installation separately.</li> <li>Configuration: Use <code>values.yaml</code> to override defaults.</li> <li>Repositories: Share charts publicly or privately.</li> </ul> <p>Helm = apt/yum/homebrew, but for Kubernetes.</p>"},{"location":"2-project/helm/#helm-architecture","title":"Helm Architecture","text":"<pre><code>   +-+\n   | Helm Client |\n   +++         +--+\n          |                |  Kubernetes API |\n          |                +--+--+\n          |                         |\n   ++-++\n   |    Kubernetes Cluster (CRDs, RBAC,    |\n   |   Deployments, Services, Secrets, etc)|\n   ++\n</code></pre> <ul> <li>Helm Client \u2192 CLI tool (<code>helm</code>).</li> <li>Release \u2192 A chart installed into a namespace with a given name.</li> <li>Chart \u2192 A bundle of templates and default values.</li> <li>Values \u2192 User configuration overrides.</li> </ul>"},{"location":"2-project/helm/#core-concepts","title":"Core Concepts","text":"Term Meaning Chart Package of Kubernetes resources. Release A deployed instance of a chart, identified by name + namespace. Values User-supplied config to customise a chart. Repository Place where charts are stored and fetched (<code>helm repo add</code>)."},{"location":"2-project/helm/#basic-commands","title":"Basic Commands","text":""},{"location":"2-project/helm/#install-a-chart","title":"Install a chart","text":"<pre><code>helm install &lt;release-name&gt; &lt;chart&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"2-project/helm/#upgrade-a-release","title":"Upgrade a release","text":"<pre><code>helm upgrade &lt;release-name&gt; &lt;chart&gt; -f values.yaml -n &lt;namespace&gt;\n</code></pre>"},{"location":"2-project/helm/#rollback-to-previous-revision","title":"Rollback to previous revision","text":"<pre><code>helm rollback &lt;release-name&gt; &lt;revision&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"2-project/helm/#list-releases","title":"List releases","text":"<pre><code>helm list -n &lt;namespace&gt;\n</code></pre>"},{"location":"2-project/helm/#uninstall-a-release","title":"Uninstall a release","text":"<pre><code>helm uninstall &lt;release-name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"2-project/helm/#managing-deployments-after-install","title":"Managing Deployments After Install","text":"<ol> <li>Scale workloads to zero (stop running without deletion)</li> </ol> <pre><code>kubectl scale deployment &lt;name&gt; --replicas=0 -n &lt;namespace&gt;\nkubectl scale statefulset &lt;name&gt; --replicas=0 -n &lt;namespace&gt;\n</code></pre> <ol> <li>Pause rollout</li> </ol> <pre><code>kubectl rollout pause deployment &lt;name&gt; -n &lt;namespace&gt;\n</code></pre> <ol> <li>Change Helm values to persist stop</li> </ol> <pre><code>replicaCount: 0\n</code></pre> <pre><code>helm upgrade &lt;release-name&gt; &lt;chart&gt; -f values.yaml -n &lt;namespace&gt;\n</code></pre>"},{"location":"2-project/helm/#helm-chart-structure","title":"Helm Chart Structure","text":"<pre><code>mychart/\n  Chart.yaml        # Metadata (name, version, description)\n  values.yaml       # Default configuration values\n  charts/           # Subcharts (dependencies)\n  templates/        # Kubernetes manifests (templated YAML)\n  templates/_helpers.tpl  # Helper template functions\n</code></pre>"},{"location":"2-project/helm/#helm-values","title":"Helm Values","text":"<p>Values control how templates render.</p> <p>Example <code>values.yaml</code>:</p> <pre><code>replicaCount: 2\nimage:\n  repository: nginx\n  tag: \"1.25.0\"\nservice:\n  type: ClusterIP\n  port: 80\n</code></pre> <p>Override values:</p> <pre><code>helm install myapp ./mychart --set replicaCount=3 --set image.tag=1.26\n</code></pre>"},{"location":"2-project/helm/#template-language","title":"Template Language","text":"<p>Helm templates use Go templating.</p> <p>Example:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ .Release.Name }}-nginx\nspec:\n  replicas: {{ .Values.replicaCount }}\n  template:\n    spec:\n      containers:\n        - name: nginx\n          image: \"{{ .Values.image.repository }}:{{ .Values.image.tag }}\"\n</code></pre>"},{"location":"2-project/helm/#helm-cheat-sheet","title":"Helm Cheat Sheet","text":""},{"location":"2-project/helm/#core-operations","title":"Core Operations","text":"Task Command Install <code>helm install &lt;release&gt; &lt;chart&gt; -n &lt;ns&gt;</code> Upgrade <code>helm upgrade &lt;release&gt; &lt;chart&gt; -f values.yaml -n &lt;ns&gt;</code> Rollback <code>helm rollback &lt;release&gt; &lt;rev&gt; -n &lt;ns&gt;</code> Delete <code>helm uninstall &lt;release&gt; -n &lt;ns&gt;</code> Diff changes <code>helm diff upgrade &lt;release&gt; &lt;chart&gt;</code> Dry run <code>helm install &lt;release&gt; &lt;chart&gt; --dry-run --debug</code>"},{"location":"2-project/helm/#chart-dev-commands","title":"Chart Dev Commands","text":"Task Command Create chart <code>helm create &lt;name&gt;</code> Lint chart <code>helm lint ./mychart</code> Package chart <code>helm package ./mychart</code> Push chart <code>helm push ./mychart oci://&lt;repo&gt;</code> Template render <code>helm template ./mychart</code>"},{"location":"2-project/helm/#security-notes","title":"Security Notes","text":"<ul> <li>Do not store plaintext secrets in <code>values.yaml</code>. Use Sealed Secrets or External Secrets Operator.</li> <li>Restrict Tiller (Helm v2 only, obsolete). Helm v3 does not need server-side components.</li> <li>Control RBAC for Helm users carefully.</li> </ul>"},{"location":"2-project/helm/#risks-trade-offs","title":"Risks &amp; Trade-offs","text":"<ul> <li>Scaling to zero via kubectl \u2192 Helm unaware, overwritten on next upgrade.</li> <li>Editing values.yaml \u2192 More controlled, but requires upgrade.</li> <li>Rollout pause \u2192 Stops updates, not running pods.</li> <li>Complex charts \u2192 Hard to debug, encourage over-abstraction.</li> </ul>"},{"location":"2-project/helm/#helm-cli-cheat-sheet","title":"Helm CLI cheat sheet","text":""},{"location":"2-project/helm/#installation-and-context","title":"Installation and context","text":"<ul> <li>Show version.</li> </ul> <pre><code>helm version\n</code></pre> <ul> <li>Show Helm env paths.</li> </ul> <pre><code>helm env\n</code></pre> <ul> <li>Set kubeconfig and context per command.</li> </ul> <pre><code>helm --kubeconfig ~/.kube/config --kube-context myctx -n myns &lt;subcommand&gt;\n</code></pre>"},{"location":"2-project/helm/#repositories-classic-index-based","title":"Repositories (classic index-based)","text":"<ul> <li>Add, update, list, remove.</li> </ul> <pre><code>helm repo add bitnami https://charts.bitnami.com/bitnami\nhelm repo update\nhelm repo list\nhelm repo remove bitnami\n</code></pre> <ul> <li>Search for charts.</li> </ul> <pre><code>helm search repo nginx\nhelm search hub wordpress            # searches Artifact Hub\n</code></pre> <ul> <li>Inspect a remote chart.</li> </ul> <pre><code>helm show chart bitnami/nginx\nhelm show values bitnami/nginx\nhelm show readme bitnami/nginx\nhelm show crds bitnami/nginx\n</code></pre> <ul> <li>Download a chart locally.</li> </ul> <pre><code>helm pull bitnami/nginx --untar --untardir ./charts\n</code></pre> <p>Reference for repo and show commands.</p>"},{"location":"2-project/helm/#oci-registries-helm-38","title":"OCI registries (Helm 3.8+)","text":"<ul> <li>Log in, push, pull.</li> </ul> <pre><code>helm registry login ghcr.io              # or ACR/ECR/Harbor\nhelm push ./mychart-0.1.0.tgz oci://ghcr.io/org/charts\nhelm pull oci://ghcr.io/org/charts/mychart --version 0.1.0 --destination ./charts\n</code></pre> <ul> <li>Install from an OCI registry.</li> </ul> <pre><code>helm install myrel oci://ghcr.io/org/charts/mychart --version 0.1.0\n</code></pre> <p>Notes on <code>oci://</code> usage and tag inference.</p>"},{"location":"2-project/helm/#install-upgrade-rollback-uninstall","title":"Install, upgrade, rollback, uninstall","text":"<ul> <li>Install.</li> </ul> <pre><code>helm install myrel bitnami/nginx -n web \\\n  -f values.yaml \\\n  --set image.tag=1.25.5 \\\n  --set-string env.MODE=prod \\\n  --set-file cert=./tls.crt \\\n  --version 15.5.0 \\\n  --create-namespace \\\n  --wait --wait-for-jobs --timeout 10m \\\n  --atomic\n</code></pre> <ul> <li>Upgrade or install if missing.</li> </ul> <pre><code>helm upgrade myrel bitnami/nginx -n web \\\n  -f values-prod.yaml \\\n  --reuse-values \\\n  --install \\\n  --wait --timeout 10m --atomic\n</code></pre> <ul> <li>Roll back.</li> </ul> <pre><code>helm history myrel -n web\nhelm rollback myrel 4 -n web --wait --timeout 10m\n</code></pre> <ul> <li>Uninstall.</li> </ul> <pre><code>helm uninstall myrel -n web                 # remove resources\nhelm uninstall myrel -n web --keep-history  # keep release secrets\n</code></pre> <p>Flags and behaviours.</p>"},{"location":"2-project/helm/#listing-and-inspecting-releases","title":"Listing and inspecting releases","text":"<ul> <li>List releases.</li> </ul> <pre><code>helm list -n web\nhelm list -A --deployed --failed -d         # sort by date\nhelm list -n web --filter '^myrel$'\n</code></pre> <ul> <li>Status and resources.</li> </ul> <pre><code>helm status myrel -n web --show-resources\n</code></pre> <ul> <li>Get rendered manifest or values used.</li> </ul> <pre><code>helm get manifest myrel -n web\nhelm get values myrel -n web                # user-supplied only\nhelm get values myrel -n web -a             # computed values\nhelm get notes myrel -n web\n</code></pre> <p>Listing and get docs.</p>"},{"location":"2-project/helm/#dry-runs-and-diffs","title":"Dry runs and diffs","text":"<ul> <li>Client or server dry run plus debug.</li> </ul> <pre><code>helm install myrel ./chart --dry-run=client --debug\nhelm upgrade myrel ./chart --dry-run=server --debug\n</code></pre> <ul> <li>Diff planned changes (plugin).</li> </ul> <pre><code>helm plugin install https://github.com/databus23/helm-diff\nhelm diff upgrade myrel ./chart -f values.yaml -n web\nhelm diff revision myrel 5 6 -n web\n</code></pre> <p>Dry-run options and diff plugin.</p>"},{"location":"2-project/helm/#values-handling-and-precedence","title":"Values handling and precedence","text":"<ul> <li>Multiple values files and flags.</li> </ul> <pre><code>helm install r ./chart -f base.yaml -f override.yaml \\\n  --set a.b=1 --set-string path=\"/var/log\" --set-file big=./blob.txt \\\n  --set-json 'features=[\"a\",\"b\"]'\n</code></pre> <ul> <li> <p>Precedence order, last one wins for repeated keys:</p> </li> <li> <p><code>--set*</code> and <code>--values</code> in right-most order.</p> </li> <li>Files listed later override earlier.</li> <li>Chart defaults are lowest.</li> </ul>"},{"location":"2-project/helm/#chart-development","title":"Chart development","text":"<ul> <li>Create, lint, render, package.</li> </ul> <pre><code>helm create mychart\nhelm lint ./mychart\nhelm template myrel ./mychart -f values.yaml &gt; all.yaml\nhelm package ./mychart -d ./dist\n</code></pre> <ul> <li>Sign and verify packages.</li> </ul> <pre><code>helm package --sign --key 'mykey' --keyring ~/.gnupg/pubring.gpg ./mychart\nhelm verify ./dist/mychart-0.1.0.tgz\n</code></pre> <ul> <li>Dependencies.</li> </ul> <pre><code># Chart.yaml: dependencies: [{ name, version, repository }]\nhelm dependency update ./mychart\nhelm dependency list ./mychart\n</code></pre> <p>Template, package, verify, and dependency docs.</p>"},{"location":"2-project/helm/#registries-and-repos-for-your-own-charts","title":"Registries and repos for your own charts","text":"<ul> <li>Classic repo index (static HTTP).</li> </ul> <pre><code>helm package ./mychart -d ./repo\nhelm repo index ./repo --url https://example.com/charts\n</code></pre> <ul> <li>OCI push to a cloud registry (example ECR).</li> </ul> <pre><code>aws ecr get-login-password | helm registry login --username AWS --password-stdin &lt;acct&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com\nhelm push ./dist/mychart-0.1.0.tgz oci://&lt;acct&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/charts\n</code></pre> <p>OCI usage references.</p>"},{"location":"2-project/helm/#post-renderers-kustomize-or-custom-binaries","title":"Post-renderers (Kustomize or custom binaries)","text":"<ul> <li>Apply last-mile patches without forking charts.</li> </ul> <pre><code>helm install myrel oci://ghcr.io/org/charts/app \\\n  --post-renderer ./kustomize-wrapper.sh\n</code></pre> <ul> <li>Works with <code>install</code>, <code>upgrade</code>, and <code>template</code>.   Post-renderer capability.</li> </ul>"},{"location":"2-project/helm/#testing-releases","title":"Testing releases","text":"<ul> <li>Define test Pods in <code>templates/</code> with <code>helm.sh/hook: test</code>.</li> <li>Run tests for a deployed release.</li> </ul> <pre><code>helm test myrel -n web --logs\n</code></pre> <p>Chart tests and <code>helm test</code> usage.</p>"},{"location":"2-project/helm/#security-and-integrity","title":"Security and integrity","text":"<ul> <li>Verify signed charts before use.</li> </ul> <pre><code>helm install myrel ./signedchart.tgz --verify --keyring ~/.gnupg/pubring.gpg\n</code></pre> <ul> <li>Prefer secrets managers for sensitive values. Use SOPS or an external secrets operator.   Provenance and verify docs.</li> </ul>"},{"location":"2-project/helm/#common-operational-patterns","title":"Common operational patterns","text":"<ul> <li>Idempotent deploy in CI.</li> </ul> <pre><code>helm upgrade --install myrel ./chart -n web -f values.yaml --wait --timeout 10m --atomic\n</code></pre> <ul> <li>Render then apply with <code>kubectl</code> when needed.</li> </ul> <pre><code>helm template myrel ./chart -f values.yaml | kubectl apply -f -\n</code></pre> <ul> <li>Stop workloads without deleting resources.</li> </ul> <pre><code># Preferred: set replicaCount: 0 in values and upgrade so Helm tracks the state\nhelm upgrade myrel ./chart -n web -f values-stop.yaml\n</code></pre> <p>Install/upgrade flags and semantics.</p>"},{"location":"2-project/helm/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>See reasons for a failed or pending release.</li> </ul> <pre><code>helm status myrel -n web\nhelm history myrel -n web\nkubectl describe pods,deploy,sts -n web\n</code></pre> <ul> <li>Retry with clean failure handling.</li> </ul> <pre><code>helm upgrade myrel ./chart -n web --cleanup-on-fail --atomic --wait --timeout 10m\n</code></pre> <p>Upgrade flags reference.</p>"},{"location":"2-project/helm/#useful-globals-and-quality-of-life","title":"Useful globals and quality-of-life","text":"<ul> <li>Completions.</li> </ul> <pre><code>helm completion bash|zsh|fish|powershell\n</code></pre> <ul> <li>Plugins.</li> </ul> <pre><code>helm plugin list\nhelm plugin install https://github.com/databus23/helm-diff\nhelm plugin update diff\nhelm plugin uninstall diff\n</code></pre> <ul> <li>Show all commands.</li> </ul> <pre><code>helm help\nhelm &lt;subcommand&gt; --help\n</code></pre> <p>Commands index and plugin guide.</p>"},{"location":"2-project/helm/#flags-worth-remembering","title":"Flags worth remembering","text":"<ul> <li><code>--namespace/-n</code>, <code>--kube-context</code>, <code>--kubeconfig</code>, <code>--wait</code>, <code>--wait-for-jobs</code>, <code>--timeout</code>, <code>--atomic</code>, <code>--cleanup-on-fail</code>, <code>--devel</code>, <code>--version</code>, <code>--dependency-update</code>, <code>--skip-crds</code>, <code>--no-hooks</code>, <code>--post-renderer</code>, <code>--set</code>, <code>--set-string</code>, <code>--set-file</code>, <code>--set-json</code>, <code>-f/--values</code>.</li> </ul>"},{"location":"2-project/helm/#risks-and-trade-offs","title":"Risks and trade-offs","text":"<ul> <li><code>kubectl scale</code> changes drift from Helm state. Persist intent in values where possible.</li> <li><code>--force</code> replaces resources and can briefly delete and recreate objects. Use with caution.</li> </ul>"},{"location":"2-project/notes/","title":"General notes before we begin","text":"<p>There are 3 Ways to Monitor Your App in Kubernetes</p>"},{"location":"2-project/notes/#1-basic-container-node-monitoring-built-in","title":"1. Basic container &amp; node monitoring (built-in)","text":"<p>Kubernetes already integrates with:</p> <ul> <li>kubelet/cAdvisor \u2192 container &amp; pod-level resource usage (CPU, memory, network, filesystem).</li> <li>Node Exporter \u2192 node-level OS metrics.</li> </ul> <p>If you deploy Prometheus (via Helm or the Operator), these metrics are automatically discovered and scraped \u2014 no extra setup required.</p>"},{"location":"2-project/notes/#2-app-specific-exporters-most-common-in-k8s","title":"2. App-specific exporters (most common in K8s)","text":"<p>Many apps expose metrics directly, or you deploy an exporter sidecar or Service:</p> <ul> <li>Nginx \u2192 nginx-prometheus-exporter</li> <li>Postgres \u2192 postgres_exporter</li> <li>MySQL \u2192 mysqld_exporter</li> <li>Redis \u2192 redis_exporter</li> </ul> <p>Example: Nginx Exporter Deployment</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:latest\n        ports:\n        - containerPort: 80\n      - name: nginx-exporter\n        image: nginx/nginx-prometheus-exporter:0.11.0\n        args:\n          - -nginx.scrape-uri=http://127.0.0.1:80/stub_status\n        ports:\n        - containerPort: 9113\n\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: nginx-exporter\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  endpoints:\n  - port: 9113\n</code></pre> <p>The <code>ServiceMonitor</code> CRD (from the Prometheus Operator) ensures Prometheus automatically discovers and scrapes the exporter.</p> <p>To list all available CRDs use:</p> <p><pre><code>kubectl get crd\n</code></pre> </p>"},{"location":"2-project/notes/#3-custom-metrics-for-apps-you-write","title":"3. Custom metrics (for apps you write)","text":"<p>If you\u2019re building your own application, you can instrument it with OpenTelemetry or a Prometheus client library:</p> <ul> <li>Go \u2192 prometheus/client_golang</li> <li>Python \u2192 prometheus_client</li> <li>Node.js \u2192 prom-client</li> </ul> <p>Example: Python Flask app exposing <code>/metrics</code></p> <pre><code>from flask import Flask\nfrom prometheus_client import Counter, generate_latest\n\napp = Flask(__name__)\nrequests_total = Counter('app_requests_total', 'Total requests')\n\n@app.route('/')\ndef hello():\n    requests_total.inc()\n    return \"Hello, Kubernetes!\"\n\n@app.route('/metrics')\ndef metrics():\n    return generate_latest(), 200, {'Content-Type': 'text/plain'}\n</code></pre> <p>Deploy the app with a Kubernetes <code>Deployment</code> and expose <code>/metrics</code>. Then define a <code>ServiceMonitor</code> to let Prometheus scrape it.</p> <ul> <li>Infra metrics \u2192 kubelet/cAdvisor + Node Exporter.</li> <li>App metrics \u2192 Exporters (Nginx, DBs, etc.) or custom instrumentation.</li> <li>Prometheus scrapes everything; Grafana dashboards visualize it.</li> </ul>"},{"location":"2-project/notes/#what-opentelemetry-adds","title":"What OpenTelemetry Adds","text":"<ul> <li>Instrumentation SDKs \u2192 for Go, Python, Java, Node.js, .NET, etc.</li> <li>Collects application metrics, traces, and optionally logs.</li> <li> <p>Works via an OpenTelemetry Collector deployed as:</p> </li> <li> <p>A sidecar (per pod)</p> </li> <li>A DaemonSet (per node)</li> <li>A Deployment (central collector)</li> </ul> <p>Backends supported:</p> <ul> <li>Prometheus (metrics)</li> <li>Jaeger / Tempo (traces)</li> <li>Loki / ELK (logs)</li> <li>Grafana Cloud or OTLP-compatible vendors</li> </ul>"},{"location":"2-project/notes/#how-it-works-in-kubernetes","title":"\ud83d\udee0 How It Works in Kubernetes","text":"<p>Right now you likely have:</p> <ul> <li>Prometheus + Grafana \u2192 metrics + visualization</li> <li>kubelet/cAdvisor + Node Exporter \u2192 infra metrics</li> </ul> <p>If you add OpenTelemetry for your app:</p> <ol> <li>Instrument your code with the OTel SDK.</li> <li>Deploy an OpenTelemetry Collector (Deployment or DaemonSet).</li> <li>Configure it to export metrics in Prometheus format (scrapable endpoint).</li> </ol>"},{"location":"2-project/notes/#example-otel-collector-in-kubernetes","title":"Example: OTel Collector in Kubernetes","text":"<p>Deploy the collector:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: otel-collector\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: otel-collector\n  template:\n    metadata:\n      labels:\n        app: otel-collector\n    spec:\n      containers:\n      - name: otel-collector\n        image: otel/opentelemetry-collector-contrib:0.95.0\n        args: [\"--config=/etc/otel/otel-collector-config.yaml\"]\n        volumeMounts:\n        - name: config\n          mountPath: /etc/otel\n      volumes:\n      - name: config\n        configMap:\n          name: otel-collector-config\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: otel-collector-config\ndata:\n  otel-collector-config.yaml: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n          http:\n\n    exporters:\n      prometheus:\n        endpoint: \"0.0.0.0:9464\"\n\n    service:\n      pipelines:\n        metrics:\n          receivers: [otlp]\n          exporters: [prometheus]\n\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: otel-collector\nspec:\n  selector:\n    matchLabels:\n      app: otel-collector\n  endpoints:\n  - port: 9464\n</code></pre> <p>Now:</p> <ul> <li>Your app sends OTLP data to the Collector (<code>4317/4318</code>).</li> <li>The Collector exposes Prometheus metrics on <code>:9464</code>.</li> <li>Prometheus scrapes them via the <code>ServiceMonitor</code>.</li> </ul>"},{"location":"2-project/notes/#why-otel-is-a-good-idea-in-kubernetes","title":"Why OTel is a Good Idea in Kubernetes","text":"<ul> <li>Cloud-native standard \u2192 portable across Prometheus, Grafana, Jaeger, Tempo, etc.</li> <li>Future-proof \u2192 works with managed observability platforms (Datadog, New Relic, Grafana Cloud, etc.).</li> <li>Full observability \u2192 unifies metrics, traces, and logs, not just CPU/memory.</li> </ul>"},{"location":"2-project/notes/#adding-any-app-to-the-stack","title":"Adding any app to the stack","text":"<p>How to instrument any app for this stack (kube-prometheus-stack, Loki, Alertmanager, Grafana). This is the app-side view only.</p>"},{"location":"2-project/notes/#1-logs-loki-via-promtail","title":"1. Logs \u2192 Loki (via Promtail)","text":"<ul> <li> <p>Best practice: apps write logs to <code>stdout/stderr</code>.</p> </li> <li> <p>Kubernetes writes container logs to <code>/var/log/containers/*.log</code>.</p> </li> <li> <p>Promtail DaemonSet (from Loki Helm chart) already tails these files.</p> </li> <li> <p>Labels: Promtail auto-labels with <code>namespace</code>, <code>pod</code>, <code>container</code>, and <code>app_kubernetes_io/name</code>.</p> </li> <li> <p>App requirements:</p> </li> <li> <p>Use structured logging (JSON preferred).</p> </li> <li> <p>Include severity, service name, request ID, etc. as fields. Promtail can parse JSON and promote fields to labels.</p> </li> <li> <p>Trade-off:</p> </li> <li> <p>Too many labels = high cardinality \u2192 Loki performance issues.</p> </li> <li>Use pipeline stages (<code>drop</code>, <code>replace</code>, <code>json</code>) to balance.</li> </ul>"},{"location":"2-project/notes/#2-metrics-prometheus","title":"2. Metrics \u2192 Prometheus","text":"<ul> <li>kube-prometheus-stack deploys Prometheus Operator with ServiceMonitor/PodMonitor CRDs.</li> <li> <p>Expose <code>/metrics</code> endpoint in the app:</p> </li> <li> <p>Prometheus client libraries exist for Go, Python, Java, Node.js, etc.</p> </li> <li> <p>Instrument key business metrics (requests, errors, durations).</p> </li> <li> <p>App requirements:</p> </li> <li> <p>Export metrics in Prometheus text format.</p> </li> <li>Add a Kubernetes <code>Service</code> with proper label selectors.</li> <li> <p>Create a <code>ServiceMonitor</code> that points to the Service.</p> </li> <li> <p>Alerting:</p> </li> <li> <p>Prometheus alerts are routed to Alertmanager, which you have configured.</p> </li> <li>Ensure metric names and labels are consistent with your alert rules.</li> </ul>"},{"location":"2-project/notes/#3-traces-opentelemetry-otel","title":"3. Traces \u2192 OpenTelemetry (OTel)","text":"<ul> <li>Use the OpenTelemetry SDK in your app to generate spans.</li> <li>Export traces to the OTel Collector running in your cluster.</li> <li> <p>Collector pipelines:</p> </li> <li> <p>Metrics \u2192 Prometheus remote-write (kube-prometheus-stack).</p> </li> <li>Logs \u2192 Loki (via OTLP \u2192 Loki exporter, or side-car Promtail).</li> <li> <p>Traces \u2192 Tempo or Jaeger (Grafana Tempo is the common pair with Loki).</p> </li> <li> <p>App requirements:</p> </li> <li> <p>Add OTel SDK instrumentation for HTTP, gRPC, DB calls.</p> </li> <li>Configure OTLP exporter to send to Collector endpoint.</li> </ul>"},{"location":"2-project/notes/#4-dashboards-grafana","title":"4. Dashboards \u2192 Grafana","text":"<ul> <li>Grafana in kube-prometheus-stack provisions Prometheus and Loki as datasources.</li> <li> <p>For app dashboards:</p> </li> <li> <p>Metrics: build panels from <code>/metrics</code> data.</p> </li> <li>Logs: query <code>{app=\"myapp\"}</code> in Explore or add log panels.</li> <li> <p>Traces: if Tempo integrated, add trace panels.</p> </li> <li> <p>Repeatability:</p> </li> <li> <p>Store dashboards as JSON in Git.</p> </li> <li>Provision them via ConfigMap + sidecar (<code>grafana_dashboard=1</code>) or GitOps pipeline.</li> </ul>"},{"location":"2-project/notes/#5-alerting","title":"5. Alerting","text":"<ul> <li>Already handled via Alertmanager.</li> <li> <p>App instrumentation must expose metrics that can be turned into SLO alerts, e.g.:</p> </li> <li> <p><code>http_requests_total</code> (rate of requests).</p> </li> <li><code>http_request_duration_seconds</code> (latency).</li> <li> <p><code>http_requests_errors_total</code> (error rate).</p> </li> <li> <p>Alerts are defined as Prometheus rules, not app-side.</p> </li> </ul>"},{"location":"2-project/notes/#6-devops-repeatability-checklist","title":"6. DevOps repeatability checklist","text":"<p>For any app:</p> <ol> <li> <p>Logging:</p> </li> <li> <p>stdout/stderr JSON logs.</p> </li> <li>Use structured fields: <code>level</code>, <code>service</code>, <code>trace_id</code>.</li> <li> <p>Confirm Promtail pipeline parses correctly.</p> </li> <li> <p>Metrics:</p> </li> <li> <p>Add Prometheus client library.</p> </li> <li>Expose <code>/metrics</code>.</li> <li> <p>Apply Service + ServiceMonitor.</p> </li> <li> <p>Tracing (optional but recommended):</p> </li> <li> <p>Add OTel SDK.</p> </li> <li> <p>Configure OTLP export \u2192 OTel Collector.</p> </li> <li> <p>Dashboards:</p> </li> <li> <p>Provision JSON dashboards via ConfigMaps or <code>grafana.dashboards</code> Helm values.</p> </li> <li> <p>Tie logs, metrics, traces together using consistent labels (e.g. <code>service_name</code>).</p> </li> <li> <p>Alerts:</p> </li> <li> <p>Define PrometheusRules based on app metrics.</p> </li> <li>Ensure routes in Alertmanager are set to notify the right channel/team.</li> </ol> <p>This makes any app pluggable into your stack: Prometheus Operator scrapes metrics, Promtail collects logs, OTel provides traces, Grafana visualises, Alertmanager handles alerts.</p> <p>Here is a golden template you can drop into any microservice repo to instrument it for your stack (kube-prometheus-stack, Loki, Grafana, Alertmanager, OpenTelemetry).</p> <p>It is language-agnostic in structure, then broken into logging, metrics, and tracing.</p>"},{"location":"2-project/notes/#golden-template-for-app-instrumentation","title":"\ud83d\udcc4 Golden Template for App Instrumentation","text":""},{"location":"2-project/notes/#1-logging-loki","title":"1. Logging \u2192 Loki","text":"<p>App code:</p> <ul> <li>Always log to <code>stdout/stderr</code>.</li> <li>Use JSON format.</li> <li>Include consistent fields:</li> </ul> <pre><code>{\n  \"timestamp\": \"2025-09-27T20:15:32Z\",\n  \"level\": \"info\",\n  \"service_name\": \"myapp\",\n  \"trace_id\": \"abc123\",\n  \"span_id\": \"def456\",\n  \"message\": \"user login success\",\n  \"http_method\": \"POST\",\n  \"http_status\": 200\n}\n</code></pre> <p>Why:</p> <ul> <li>Promtail DaemonSet already tails <code>/var/log/containers/*.log</code>.</li> <li>JSON fields can be promoted to Loki labels (<code>http_status</code>, <code>level</code>, <code>service_name</code>).</li> </ul> <p>Promtail pipeline (values.yaml snippet):</p> <pre><code>extraScrapeConfigs: |\n  - job_name: kubernetes-pods-apps\n    pipeline_stages:\n      - json:\n          expressions:\n            level: level\n            service_name: service_name\n            http_status: http_status\n      - labels:\n          level:\n          service_name:\n          http_status:\n</code></pre>"},{"location":"2-project/notes/#2-metrics-prometheus_1","title":"2. Metrics \u2192 Prometheus","text":"<p>App code:</p> <ul> <li>Import Prometheus client library.</li> <li>Expose <code>/metrics</code> endpoint.</li> </ul> <p>Example (Python / FastAPI):</p> <pre><code>from prometheus_client import Counter, Histogram, generate_latest\nfrom fastapi import FastAPI, Response, Request\nimport time\n\napp = FastAPI()\n\nREQ_COUNT = Counter(\"http_requests_total\", \"Total requests\", [\"method\", \"endpoint\", \"http_status\"])\nREQ_LATENCY = Histogram(\"http_request_duration_seconds\", \"Request latency\", [\"method\", \"endpoint\"])\n\n@app.middleware(\"http\")\nasync def metrics_middleware(request: Request, call_next):\n    start = time.time()\n    response = await call_next(request)\n    duration = time.time() - start\n    REQ_COUNT.labels(request.method, request.url.path, response.status_code).inc()\n    REQ_LATENCY.labels(request.method, request.url.path).observe(duration)\n    return response\n\n@app.get(\"/metrics\")\nasync def metrics():\n    return Response(content=generate_latest(), media_type=\"text/plain\")\n</code></pre> <p>Kubernetes Service:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\n  labels:\n    app: myapp\nspec:\n  ports:\n    - name: http\n      port: 80\n      targetPort: 8080\n  selector:\n    app: myapp\n</code></pre> <p>ServiceMonitor:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: myapp\n  labels:\n    release: kube-prometheus-stack\nspec:\n  selector:\n    matchLabels:\n      app: myapp\n  endpoints:\n    - port: http\n      path: /metrics\n      interval: 30s\n</code></pre>"},{"location":"2-project/notes/#3-tracing-opentelemetry","title":"3. Tracing \u2192 OpenTelemetry","text":"<p>App code (Python / FastAPI example):</p> <pre><code>from opentelemetry import trace\nfrom opentelemetry.instrumentation.fastapi import FastAPIInstrumentor\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\n# Configure tracer\nprovider = TracerProvider()\nprocessor = BatchSpanProcessor(OTLPSpanExporter(endpoint=\"http://otel-collector:4318/v1/traces\"))\nprovider.add_span_processor(processor)\ntrace.set_tracer_provider(provider)\n\n# Instrument FastAPI\nFastAPIInstrumentor().instrument_app(app)\n</code></pre> <p>Collector config (values.yaml for opentelemetry-collector):</p> <pre><code>config:\n  receivers:\n    otlp:\n      protocols:\n        http:\n        grpc:\n\n  exporters:\n    loki:\n      endpoint: http://loki-gateway.k8s-monitoring-ns.svc.cluster.local/loki/api/v1/push\n    prometheus:\n      endpoint: \"0.0.0.0:8889\"\n    tempo:\n      endpoint: http://tempo:4317\n      insecure: true\n\n  service:\n    pipelines:\n      traces:\n        receivers: [otlp]\n        exporters: [tempo]\n      metrics:\n        receivers: [otlp]\n        exporters: [prometheus]\n      logs:\n        receivers: [otlp]\n        exporters: [loki]\n</code></pre>"},{"location":"2-project/notes/#4-dashboards-grafana_1","title":"4. Dashboards \u2192 Grafana","text":"<ul> <li>Store dashboards as JSON in Git.</li> <li>Provision using ConfigMap with <code>grafana_dashboard: \"1\"</code> label.</li> </ul> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: myapp-dashboard\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  myapp-dashboard.json: |\n    { \"title\": \"MyApp Dashboard\", \"panels\": [...] }\n</code></pre>"},{"location":"2-project/notes/#5-alerts-alertmanager","title":"5. Alerts \u2192 Alertmanager","text":"<ul> <li>Write PrometheusRule CRs for your app metrics.</li> </ul> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: myapp-rules\nspec:\n  groups:\n    - name: myapp.rules\n      rules:\n        - alert: HighErrorRate\n          expr: rate(http_requests_total{http_status=~\"5..\"}[5m]) &gt; 0.05\n          for: 2m\n          labels:\n            severity: warning\n          annotations:\n            summary: \"High error rate for myapp\"\n            description: \"More than 5% of requests are failing\"\n</code></pre>"},{"location":"2-project/notes/#checklist-for-any-app","title":"Checklist for any app","text":"<ul> <li> Logs in JSON to <code>stdout</code>.</li> <li> Prometheus client library, <code>/metrics</code> endpoint.</li> <li> OTel SDK exporting to Collector.</li> <li> Service + ServiceMonitor in cluster.</li> <li> Dashboard JSON under Git.</li> <li> PrometheusRule alerts defined.</li> </ul> <p>Later you clould package this into a starter Helm chart skeleton for apps so you can just scaffold new services with logging, metrics, and tracing prewired?</p>"},{"location":"2-project/portainer/","title":"Portainer","text":""},{"location":"2-project/portainer/#what-is-portainer","title":"What is Portainer?","text":"<p>Portainer is an open-source container management platform that provides a graphical user interface (GUI) and API for managing:</p> <ul> <li>Docker</li> <li>Kubernetes</li> <li>Docker Swarm</li> <li>Nomad</li> </ul> <p>It simplifies container lifecycle management, making it easy for both beginners and experienced DevOps engineers to manage infrastructure without deep CLI expertise.</p> <p>Think of Portainer as the \"control panel\" for containers and clusters.</p>"},{"location":"2-project/portainer/#why-do-we-need-portainer","title":"Why Do We Need Portainer?","text":"<p>Modern container platforms (Docker/Kubernetes) are:</p> <ul> <li>Powerful but complex \u2192 require CLI + YAML configs.</li> <li>Time-consuming \u2192 repetitive management tasks.</li> <li>Multi-cluster \u2192 managing different environments is hard.</li> </ul> <p>Portainer solves this by:</p> <ul> <li>Giving a web-based UI.</li> <li>Managing apps, networks, volumes, configs, secrets in one place.</li> <li>Enabling role-based access control (RBAC).</li> <li>Supporting multi-environment setups (Docker, K8s, Swarm, Nomad).</li> </ul>"},{"location":"2-project/portainer/#core-features-of-portainer","title":"Core Features of Portainer","text":"<ol> <li> <p>Universal Platform Support</p> </li> <li> <p>Docker Standalone</p> </li> <li>Docker Swarm</li> <li>Kubernetes</li> <li> <p>Nomad</p> </li> <li> <p>Application Deployment</p> </li> <li> <p>Deploy apps via UI forms or YAML manifests.</p> </li> <li> <p>Built-in App Templates for one-click deployments.</p> </li> <li> <p>Cluster Management</p> </li> <li> <p>Node/Pod/Container monitoring.</p> </li> <li>Scaling services (add/remove replicas).</li> <li> <p>Network + volume management.</p> </li> <li> <p>User Management &amp; RBAC</p> </li> <li> <p>Fine-grained access controls.</p> </li> <li> <p>Teams, roles, namespaces.</p> </li> <li> <p>Security</p> </li> <li> <p>Centralised secrets management.</p> </li> <li> <p>Registry credentials management.</p> </li> <li> <p>Multi-Cluster / Multi-Environment</p> </li> <li> <p>Manage multiple clusters from one dashboard.</p> </li> </ol>"},{"location":"2-project/portainer/#portainer-architecture","title":"Portainer Architecture","text":"<pre><code>flowchart TD\n\n    subgraph User[\"Users/Admins\"]\n        U1[\"Web Browser (UI)\"]\n        U2[\"API Clients\"]\n    end\n\n    subgraph Portainer[\"Portainer Server\"]\n        UI[\"Web UI\"]\n        API[\"REST API\"]\n        DB[\"Internal Database (BoltDB/MySQL/Postgres)\"]\n        AG[\"Portainer Agent\"]\n    end\n\n    subgraph Environments[\"Container Environments\"]\n        D[\"Docker\"]\n        S[\"Docker Swarm\"]\n        K[\"Kubernetes\"]\n        N[\"Nomad\"]\n    end\n\n    U1 --&gt; UI\n    U2 --&gt; API\n    UI --&gt; DB\n    API --&gt; DB\n    Portainer --&gt; AG\n    AG --&gt; D\n    AG --&gt; S\n    AG --&gt; K\n    AG --&gt; N</code></pre>"},{"location":"2-project/portainer/#explanation-of-the-flow","title":"Explanation of the Flow","text":"<ol> <li>Users interact via browser UI or API clients.</li> <li>Portainer Server handles UI, API, authentication, and persistence.</li> <li>Portainer Agent runs inside the cluster, gathering environment data.</li> <li>Environments (Docker/K8s/etc.) are managed through the agent.</li> </ol>"},{"location":"2-project/portainer/#user-flow-in-portainer","title":"User Flow in Portainer","text":"<pre><code>sequenceDiagram\n    participant User as User\n    participant UI as Portainer UI\n    participant API as Portainer API\n    participant Agent as Portainer Agent\n    participant Env as Docker/Kubernetes/Swarm/Nomad\n\n    User-&gt;&gt;UI: Log in\n    UI-&gt;&gt;API: Request (create container, deploy app, etc.)\n    API-&gt;&gt;Agent: Send management command\n    Agent-&gt;&gt;Env: Apply changes (create container/pod)\n    Env--&gt;&gt;Agent: Status update\n    Agent--&gt;&gt;API: Response\n    API--&gt;&gt;UI: Show updated status\n    UI--&gt;&gt;User: Display results</code></pre>"},{"location":"2-project/portainer/#key-strengths-of-portainer","title":"Key Strengths of Portainer","text":"<ul> <li>Ease of Use \u2192 GUI + templates for beginners.</li> <li>Multi-platform \u2192 Manage Docker, Swarm, Kubernetes, Nomad.</li> <li>RBAC \u2192 Role-based access control for teams.</li> <li>Security \u2192 Secrets, registries, LDAP integration.</li> <li>Centralised \u2192 Manage multiple clusters/environments in one place.</li> <li>Quick Learning Curve \u2192 Great for onboarding DevOps teams.</li> </ul>"},{"location":"2-project/portainer/#limitations-watch-outs","title":"Limitations &amp; Watch Outs","text":"<ul> <li>Abstracts Complexity \u2192 advanced Kubernetes users may find it restrictive.</li> <li>Enterprise Features (RBAC, registry management, OAuth) \u2192 only in Portainer Business Edition.</li> <li>Not a Monitoring Tool \u2192 needs to integrate with Prometheus/Grafana for observability.</li> <li>Scaling \u2192 UI may become less efficient for very large clusters (&gt;1k nodes).</li> </ul>"},{"location":"2-project/portainer/#portainer-editions","title":"Portainer Editions","text":"Edition Use Case Key Features Community Edition (CE) Free, for small teams Manage Docker, Swarm, K8s; UI; templates Business Edition (BE) Enterprise setups RBAC, SSO (LDAP, OAuth, AD), support, audit logs, advanced security"},{"location":"2-project/portainer/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>Learning Kubernetes/Docker with less CLI hassle.</li> <li>SMBs running Docker/Swarm with limited DevOps expertise.</li> <li>Enterprises using BE for governance + RBAC.</li> <li>CI/CD pipelines \u2192 quick visual deployment + rollback.</li> </ul>"},{"location":"2-project/portainer/#deployment-examples","title":"Deployment Examples","text":""},{"location":"2-project/portainer/#1-deploy-portainer-in-docker","title":"1. Deploy Portainer in Docker","text":"<pre><code>docker volume create portainer_data\n\ndocker run -d \\\n  -p 8000:8000 \\\n  -p 9443:9443 \\\n  --name portainer \\\n  --restart=always \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v portainer_data:/data \\\n  portainer/portainer-ce:latest\n</code></pre> <ul> <li>Runs Portainer CE.</li> <li>Accessible at <code>https://localhost:9443</code>.</li> </ul>"},{"location":"2-project/portainer/#2-deploy-portainer-in-kubernetes","title":"2. Deploy Portainer in Kubernetes","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: portainer\n  namespace: portainer\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: portainer\n  template:\n    metadata:\n      labels:\n        app: portainer\n    spec:\n      containers:\n        - name: portainer\n          image: portainer/portainer-ce:latest\n          ports:\n            - containerPort: 9443\n          volumeMounts:\n            - name: portainer-data\n              mountPath: /data\n      volumes:\n        - name: portainer-data\n          persistentVolumeClaim:\n            claimName: portainer-pvc\n</code></pre>"},{"location":"2-project/portainer/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Restrict access to the Portainer UI with TLS + strong auth.</li> <li>Use RBAC to enforce least privilege.</li> <li>Integrate with LDAP/OAuth/AD (BE only).</li> <li>Don\u2019t expose Docker socket (<code>/var/run/docker.sock</code>) publicly.</li> <li>Apply network policies in Kubernetes.</li> </ul>"},{"location":"2-project/portainer/#portainer-vs-alternatives","title":"Portainer vs Alternatives","text":"Tool Focus Strengths Weaknesses Portainer UI for container mgmt Easy, multi-platform, RBAC Limited advanced K8s features Rancher Full K8s management Multi-cluster, monitoring, CI/CD More complex, heavier Lens IDE K8s desktop client Dev-friendly, visual dashboards No Docker/Swarm support Docker Desktop Local Docker dev Simple local setup Not for production"},{"location":"2-project/portainer/#portainer-cheat-sheet","title":"Portainer Cheat Sheet","text":""},{"location":"2-project/portainer/#key-concepts","title":"Key Concepts","text":"Term Meaning Environment Cluster or Docker endpoint managed by Portainer Agent Lightweight connector between Portainer and environments Stack Group of services deployed together (like Docker Compose) App Template Predefined configuration for quick app deployment RBAC Role-based access control for multi-user environments"},{"location":"2-project/portainer/#useful-commands","title":"Useful Commands","text":"<p>Deploy Portainer on Docker</p> <pre><code>docker run -d -p 9443:9443 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce\n</code></pre> <p>Add Kubernetes Environment (via CLI)</p> <pre><code>kubectl create namespace portainer\nkubectl apply -n portainer -f https://downloads.portainer.io/portainer-agent-k8s.yaml\n</code></pre>"},{"location":"2-project/portainer/#final-takeaway","title":"Final Takeaway","text":"<p>Portainer is:</p> <ul> <li>Beginner-friendly \u2192 perfect for teams learning Docker/K8s.</li> <li>Multi-platform \u2192 one UI for Docker, Swarm, Kubernetes, Nomad.</li> <li>Secure &amp; Enterprise-ready (in BE) \u2192 RBAC, SSO, auditing.</li> <li>Not a replacement for monitoring/logging \u2192 should be paired with Prometheus, Grafana, Loki, etc.</li> </ul> <p>If you want a centralised, easy-to-use container management dashboard, Portainer is an excellent choice.</p>"},{"location":"2-project/portainer/#how-portainer-works-in-swarm","title":"How Portainer Works in Swarm","text":"<p>You don\u2019t need to attach your application containers (Grafana, Prometheus, nginx, etc.) to the <code>agent_network</code> that Portainer uses.</p> <ul> <li>Portainer Server talks to the Portainer Agent(s) over the <code>agent_network</code> only.</li> <li>The Agent runs on every node (mode: global) and connects to the local Docker API (<code>/var/run/docker.sock</code>).</li> <li>Through the Agent, Portainer can see all containers, networks, and volumes, regardless of which network your app services are attached to.</li> </ul> <p>So, even if your app containers are only on the <code>monitoring</code> network, Portainer will still discover and manage them because the agent queries the Docker API on that node.</p>"},{"location":"2-project/portainer/#when-to-use-agent_network","title":"When to Use <code>agent_network</code>","text":"<ul> <li>Only the Portainer server and Portainer agents need to be on <code>agent_network</code>.</li> <li>Other stacks/services (Grafana, Prometheus, nginx, etc.) stay on their own networks (<code>monitoring</code>, etc.).</li> <li>Portainer will still list them in the UI because it talks to Docker/Swarm, not directly over the app network.</li> </ul>"},{"location":"2-project/portainer/#when-not-to-add-to-agent_network","title":"When NOT to Add to <code>agent_network</code>","text":"<ul> <li>You don\u2019t want all your app services unnecessarily exposed to the Portainer service network.</li> <li>It can clutter the DNS namespace and increase security exposure.</li> </ul> <p>Best Practice Setup:</p> <ul> <li>Portainer/Agent \u2192 use <code>agent_network</code>.</li> <li>Your app stack (Prometheus, Grafana, etc.) \u2192 use their own networks (<code>monitoring</code>, etc.).</li> <li>No need to mix them.</li> </ul>"},{"location":"2-project/portainer/#how-swarm-stacks-work","title":"How Swarm Stacks Work","text":"<p>You can (and usually should) keep Portainer in its own stack, separate from your monitoring stack.</p> <ul> <li> <p>Each <code>docker stack deploy</code> creates a namespace in Swarm.</p> </li> <li> <p>Example:</p> <pre><code>docker stack deploy -c monitoring.yml monitoring\ndocker stack deploy -c portainer.yml portainer\n</code></pre> </li> <li> <p>Services in stack <code>monitoring</code> are prefixed like:</p> <pre><code>monitoring_grafana\nmonitoring_prometheus\n</code></pre> </li> <li> <p>Services in stack <code>portainer</code> are prefixed like:</p> <pre><code>portainer_portainer\nportainer_agent\n</code></pre> </li> <li> <p>Networks are also namespaced unless you create them externally.</p> </li> <li> <p><code>monitoring</code> network \u2192 <code>monitoring_monitoring</code></p> </li> <li><code>agent_network</code> \u2192 <code>portainer_agent_network</code></li> </ul>"},{"location":"2-project/portainer/#portainer-stack-standalone","title":"Portainer Stack (Standalone)","text":"<p>Portainer only needs:</p> <ul> <li><code>agent_network</code> (overlay) for server \u2194 agents communication.</li> <li><code>portainer_data</code> volume.</li> </ul> <p>It does not need the <code>monitoring</code> network.</p>"},{"location":"2-project/portainer/#monitoring-stack-standalone","title":"Monitoring Stack (Standalone)","text":"<p>Prometheus, Grafana, exporters, etc. only need:</p> <ul> <li><code>monitoring</code> network.</li> <li>Their own volumes/configs.</li> </ul> <p>They do not need the <code>agent_network</code>.</p>"},{"location":"2-project/portainer/#how-portainer-sees-other-stacks","title":"How Portainer Sees Other Stacks","text":"<ul> <li>The Portainer Agent talks to the Docker API socket on each node.</li> <li>That API knows about all stacks, services, volumes, networks, and tasks in the Swarm.</li> <li>So Portainer will display your monitoring stack in the UI automatically, even though it\u2019s on a completely different network.</li> </ul> <p>No need to manually connect <code>monitoring</code> stack services to the <code>agent_network</code>.</p>"},{"location":"2-project/portainer/#best-practice","title":"Best Practice","text":"<ul> <li>Deploy Portainer stack separately (<code>docker stack deploy -c portainer.yml portainer</code>).</li> <li>Deploy Monitoring stack separately (<code>docker stack deploy -c monitoring.yml monitoring</code>).</li> <li>Keep networks isolated per stack, unless you explicitly need inter-stack communication.</li> <li>Only use external overlay networks if two stacks need to talk to each other.</li> </ul> <p>Analogy: Think of Portainer as a control tower.</p> <ul> <li>It doesn\u2019t sit on the same runway as planes (your apps).</li> <li>It just talks to the airport radar (Docker API) to know what planes are out there and manage them.</li> </ul>"},{"location":"2-project/prometheus/","title":"What is Prometheus?","text":"<p>Prometheus is an open-source monitoring and alerting toolkit designed for time-series data (metrics with timestamps). It was created at SoundCloud and is now a CNCF graduated project (same foundation as Kubernetes).</p> <p>Prometheus has become the de facto standard for monitoring in cloud-native environments, especially with Kubernetes, due to its scalability, flexibility, and ecosystem.</p>"},{"location":"2-project/prometheus/#why-do-we-need-monitoring","title":"Why Do We Need Monitoring?","text":"<p>Modern systems are:</p> <ul> <li>Distributed (many services, microservices, containers).</li> <li>Dynamic (instances scale up and down).</li> <li>Complex (multiple dependencies, networks, storage).</li> </ul> <p>Without monitoring, failures remain invisible until users complain.</p> <p>Monitoring answers:</p> <ul> <li>Is my service up?</li> <li>How much traffic am I serving?</li> <li>Are we running into errors, bottlenecks, or slowdowns?</li> <li>When should we scale?</li> </ul> <p>Monitoring data comes in three main forms (the \u201cthree pillars of observability\u201d):</p> <ol> <li>Logs \u2192 Event-based, detailed messages.</li> <li>Metrics \u2192 Numeric measurements over time (cheap, efficient).</li> <li>Traces \u2192 End-to-end request tracking.</li> </ol> <p>Prometheus focuses on metrics.</p>"},{"location":"2-project/prometheus/#time-series-basics","title":"Time-Series Basics","text":"<p>A time series is a sequence of values recorded at successive points in time. Example:</p> Time Metric Value 10:00 CPU usage 30% 10:01 CPU usage 32% 10:02 CPU usage 31% <p>Each metric in Prometheus is:</p> <ul> <li>Metric name \u2192 <code>http_requests_total</code></li> <li>Labels (key-value pairs for context) \u2192 <code>{method=\"GET\", status=\"200\"}</code></li> <li>Timestamp + value</li> </ul> <p>This allows very powerful queries like: \u201cHow many <code>GET</code> requests per second returned a <code>500</code> error in the last 5 minutes?\u201d</p>"},{"location":"2-project/prometheus/#video-introduction","title":"Video Introduction","text":""},{"location":"2-project/prometheus/#how-prometheus-works","title":"How Prometheus Works","text":"<p>Prometheus is built around a pull-based model:</p> <ol> <li>Targets expose metrics via HTTP (usually at <code>/metrics</code>).</li> <li>Prometheus scrapes metrics at regular intervals.</li> <li>Data is stored in its own time-series database (TSDB).</li> <li>Metrics can be queried using PromQL (Prometheus Query Language).</li> <li>Alerting rules can trigger alerts via Alertmanager.</li> <li>For short-lived jobs, metrics can be pushed via Pushgateway.</li> </ol>"},{"location":"2-project/prometheus/#architecture-overview","title":"Architecture Overview","text":"<pre><code>          +-+\n          |    Applications   |\n          |  Export metrics   |\n          +++\n                    |\n                    v\n          +++\n          |  Exporters        |   (e.g. node_exporter, redis_exporter)\n          +++\n                    |\n                    v\n          +++\n          | Prometheus Server |   (scrapes, stores, queries data)\n          +++\n               |          |\n         (alerts)    (queries)\n               |          |\n          +-v-+ +v+\n          |Alertmgr | | Grafana|\n          ++ +--+\n</code></pre>"},{"location":"2-project/prometheus/#metric-flow-from-app-prometheus-user","title":"Metric Flow: From App \u2192 Prometheus \u2192 User","text":"<pre><code>sequenceDiagram\n    participant App as Application\n    participant Exp as Exporter (/metrics)\n    participant Prom as Prometheus Server\n    participant Graf as Grafana\n    participant AM as Alertmanager\n    participant User as User / SRE\n\n    App-&gt;&gt;Exp: Expose metrics (HTTP /metrics)\n    Prom-&gt;&gt;Exp: Scrape metrics (pull)\n    Prom-&gt;&gt;Prom: Store in TSDB (time-series DB)\n    User-&gt;&gt;Graf: Request dashboard\n    Graf-&gt;&gt;Prom: Query via PromQL\n    Prom--&gt;&gt;Graf: Return metrics\n    Graf--&gt;&gt;User: Display visualization\n\n    Prom-&gt;&gt;Prom: Evaluate alert rules\n    Prom-&gt;&gt;AM: Send alert\n    AM--&gt;&gt;User: Notify (Slack/Email/PagerDuty)</code></pre>"},{"location":"2-project/prometheus/#explanation-of-the-flow","title":"Explanation of the Flow","text":"<ol> <li>App \u2192 exposes metrics (or uses an exporter).</li> <li>Prometheus \u2192 regularly scrapes metrics via HTTP pull.</li> <li>Prometheus TSDB \u2192 stores the metrics with timestamps.</li> <li>Grafana \u2192 users query metrics with PromQL and visualise them.</li> <li>Alertmanager \u2192 gets triggered if rules match (CPU &gt; 90%, target down, etc.).</li> <li>User (SRE/DevOps) \u2192 gets notified and investigates.</li> </ol>"},{"location":"2-project/prometheus/#key-strengths-of-prometheus","title":"Key Strengths of Prometheus","text":"<ul> <li>Standalone: no external database required.</li> <li>PromQL: powerful and flexible query language for metrics.</li> <li>Kubernetes-native: integrates seamlessly with service discovery.</li> <li>Ecosystem: works with Grafana, Alertmanager, Pushgateway, Thanos, Cortex.</li> <li>Scalable: handles thousands of metrics and targets efficiently.</li> </ul>"},{"location":"2-project/prometheus/#limitations-watch-outs","title":"Limitations &amp; Watch Outs","text":"<ul> <li> <p>Not ideal for long-term storage \u2192 data retention is limited (usually weeks).   \u2192 Solution: use Thanos, Cortex, or Mimir.</p> </li> <li> <p>High cardinality \u2192 too many unique label combinations can overwhelm memory.   \u2192 Example: <code>user_id</code> as a label = millions of unique values.</p> </li> <li> <p>Pull model challenges \u2192 doesn\u2019t fit well with:</p> </li> <li> <p>Short-lived jobs (use Pushgateway).</p> </li> <li> <p>Firewalled environments.</p> </li> <li> <p>No built-in dashboards \u2192 always paired with Grafana.</p> </li> </ul>"},{"location":"2-project/prometheus/#promql-the-query-language","title":"PromQL \u2014 The Query Language","text":"<p>Prometheus comes with PromQL (Prometheus Query Language), which lets you slice, dice, and aggregate metrics. Think of it as SQL for time-series data.</p>"},{"location":"2-project/prometheus/#selectors","title":"Selectors","text":"<pre><code>http_requests_total\nhttp_requests_total{job=\"api\"}\nup == 0\n</code></pre>"},{"location":"2-project/prometheus/#aggregations","title":"Aggregations","text":"<pre><code>sum(http_requests_total)\navg(http_requests_total)\nmax(http_requests_total)\nmin(http_requests_total)\ncount(http_requests_total)\nsum by (job)(http_requests_total)\navg by (instance)(up)\n</code></pre>"},{"location":"2-project/prometheus/#rate-increase","title":"Rate &amp; Increase","text":"<pre><code>rate(http_requests_total[1m])\nincrease(http_requests_total[5m])\n</code></pre>"},{"location":"2-project/prometheus/#common-alert-conditions","title":"Common Alert Conditions","text":"<pre><code>rate(http_requests_total[5m]) &gt; 100\nnode_memory_Active_bytes / node_memory_MemTotal_bytes &gt; 0.9\nup == 0\n</code></pre>"},{"location":"2-project/prometheus/#alerting-with-prometheus-alertmanager","title":"Alerting with Prometheus + Alertmanager","text":"<p>Prometheus defines alert rules. When triggered, alerts are sent to Alertmanager, which handles:</p> <ul> <li>Routing (who should be notified?).</li> <li>Silencing (ignore alerts during maintenance).</li> <li>Grouping (combine related alerts).</li> <li>Delivery (email, Slack, PagerDuty, etc.).</li> </ul>"},{"location":"2-project/prometheus/#example-alert-rule","title":"Example Alert Rule","text":"<pre><code>groups:\n  - name: example.rules\n    rules:\n      - alert: HighCPUUsage\n        expr: rate(process_cpu_seconds_total[1m]) &gt; 0.85\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High CPU usage on {{ $labels.instance }}\"\n          description: \"CPU &gt; 85% for 2 minutes.\"\n</code></pre>"},{"location":"2-project/prometheus/#metric-types-in-prometheus","title":"Metric Types in Prometheus","text":"Type Use For Example <code>counter</code> Monotonically increasing values <code>http_requests_total</code> (total requests) <code>gauge</code> Arbitrary values (up &amp; down) <code>memory_usage_bytes</code>, <code>temperature_c</code> <code>histogram</code> Buckets of observations (distribution) Request latency buckets <code>summary</code> Similar to histogram, client-calculated Percentiles of request durations"},{"location":"2-project/prometheus/#common-exporters","title":"Common Exporters","text":"<p>Prometheus itself doesn\u2019t know about your apps \u2014 exporters bridge the gap.</p> Exporter Purpose <code>node_exporter</code> Host/system metrics (CPU, memory, disk) <code>blackbox_exporter</code> Probes HTTP, TCP, DNS endpoints <code>postgres_exporter</code> PostgreSQL database metrics <code>redis_exporter</code> Redis performance metrics <code>nginx_exporter</code> Nginx server stats <code>cadvisor</code> Container runtime (Docker, Kubernetes) <code>kube-state-metrics</code> Kubernetes object states (Pods, Deploys)"},{"location":"2-project/prometheus/#prometheus-configuration","title":"Prometheus Configuration","text":"<p>Prometheus is configured using a YAML file (<code>prometheus.yml</code>). The most important part is <code>scrape_configs</code>.</p> <pre><code>scrape_configs:\n  - job_name: 'django-app'\n    static_configs:\n      - targets: ['localhost:8001']\n</code></pre> <ul> <li><code>job_name</code>: Logical name for the service.</li> <li><code>targets</code>: Endpoints exposing <code>/metrics</code>.</li> </ul>"},{"location":"2-project/prometheus/#security-best-practices","title":"Security Best Practices","text":"<p>Prometheus itself has minimal security features:</p> <ul> <li>Don\u2019t expose Prometheus directly to the public internet.</li> <li>Put it behind a reverse proxy with authentication.</li> <li>Enable TLS for cross-network metrics.</li> <li>Avoid sensitive labels (<code>user_id</code>, <code>token</code>).</li> <li>Monitor Prometheus itself (<code>up</code>, <code>scrape_duration_seconds</code>).</li> </ul>"},{"location":"2-project/prometheus/#scaling-long-term-storage","title":"Scaling &amp; Long-Term Storage","text":"<p>Prometheus is single-node by design. For large scale:</p> <ul> <li>Thanos \u2192 object storage for long-term retention.</li> <li>Cortex / Mimir \u2192 horizontally scalable, multi-tenant.</li> <li>Federation \u2192 aggregate across Prometheus servers.</li> </ul>"},{"location":"2-project/prometheus/#comparison-with-alternatives","title":"Comparison with Alternatives","text":"Tool Type Strengths Weaknesses Prometheus Open-source CNCF standard, Kubernetes-native No long-term storage InfluxDB Time-series DB SQL-like query (Flux), dashboards Less Kubernetes-native Datadog SaaS Turnkey, integrations, great UI Expensive, vendor lock-in New Relic SaaS APM Tracing + metrics + logs Cost, complexity Graphite Legacy OSS Simple, widely used historically Aging ecosystem"},{"location":"2-project/prometheus/#prometheus-thanos-architecture","title":"Prometheus + Thanos Architecture","text":""},{"location":"2-project/prometheus/#core-prometheus","title":"Core Prometheus","text":"<pre><code>flowchart TD\n\n    subgraph Apps[Applications &amp; Services]\n        A1[App 1] --&gt;|/metrics| E1[Exporter]\n        A2[App 2] --&gt;|/metrics| E2[Exporter]\n        A3[Database] --&gt;|/metrics| E3[Exporter]\n    end\n\n    subgraph PrometheusCore[Prometheus Server]\n        P[Prometheus]\n    end\n\n    E1 --&gt; P\n    E2 --&gt; P\n    E3 --&gt; P\n\n    P --&gt;|Queries| Grafana[(Grafana Dashboards)]\n    P --&gt;|Alerts| Alertmanager[(Alertmanager)]</code></pre>"},{"location":"2-project/prometheus/#prometheus-with-thanos","title":"Prometheus with Thanos","text":"<pre><code>flowchart TD\n\n    subgraph AppLayer[\"Applications &amp; Services\"]\n        A1[\"App 1\"] --&gt;|/metrics| E1[Exporter]\n        A2[\"App 2\"] --&gt;|/metrics| E2[Exporter]\n        A3[\"Database\"] --&gt;|/metrics| E3[Exporter]\n    end\n\n    subgraph PrometheusCluster[\"Prometheus Servers\"]\n        P1[\"Prometheus #1\"]\n        P2[\"Prometheus #2\"]\n    end\n\n    E1 --&gt; P1\n    E2 --&gt; P1\n    E3 --&gt; P2\n\n    subgraph Thanos[\"Thanos Components\"]\n        Q[\"Thanos Querier\"]\n        S[\"Thanos Sidecar\"]\n        G[\"Thanos Store Gateway\"]\n        C[\"Object Storage (S3/GCS/Azure)\"]\n    end\n\n    P1 --&gt; S\n    P2 --&gt; S\n    S --&gt; C\n    C --&gt; G\n    G --&gt; Q\n    P1 --&gt; Q\n    P2 --&gt; Q\n\n    Q --&gt; Grafana[\"Grafana Dashboards\"]\n    Q --&gt; Alertmanager[\"Alertmanager\"]</code></pre>"},{"location":"2-project/prometheus/#final-takeaway","title":"Final Takeaway","text":"<p>Prometheus is:</p> <ul> <li>Simple to start.</li> <li>Powerful with PromQL.</li> <li>Scalable with Thanos/Cortex.</li> <li>Best choice for Kubernetes and microservices monitoring.</li> </ul>"},{"location":"2-project/reading_dashboards/","title":"DevOps Dashboard Cheat Sheet","text":"<p>How to read dashboards &amp; diagnose issues like a pro</p>"},{"location":"2-project/reading_dashboards/#the-big-picture-why-dashboards-matter","title":"The Big Picture \u2014 Why Dashboards Matter","text":"<p>Dashboards are not just \u201cpretty graphs\u201d \u2014 they answer 3 core questions:</p> <ol> <li>Is it up? \u2192 availability (can users access it?)</li> <li>Is it fast? \u2192 performance (is it responsive?)</li> <li>Is it healthy? \u2192 resource health (can it stay running?)</li> </ol> <p>Tip</p> <p>Always think in terms of symptoms \u2192 cause. For example: \u201cWebsite is slow\u201d (symptom) \u2192 \u201cdatabase CPU 100%\u201d (cause).</p>"},{"location":"2-project/reading_dashboards/#core-areas-to-monitor","title":"Core Areas to Monitor","text":""},{"location":"2-project/reading_dashboards/#1-cpu","title":"1. CPU","text":"<ul> <li> <p>What to look for:</p> </li> <li> <p><code>% usage</code> per core and overall.</p> </li> <li>Breakdown: system, user, iowait.</li> <li> <p>Rules of thumb:</p> </li> <li> <p>&lt;70% sustained \u2192 healthy.</p> </li> <li> <p>90% sustained \u2192 CPU bottleneck.</p> </li> <li> <p>What it means:</p> </li> <li> <p>High user CPU \u2192 app code is working hard (expected under load).</p> </li> <li>High system CPU \u2192 kernel, syscalls, maybe networking overhead.</li> <li>High iowait \u2192 CPU is waiting on disk/network \u2192 possible I/O bottleneck.</li> <li> <p>Actions:</p> </li> <li> <p>Add replicas / scale service.</p> </li> <li>Profile app (optimize queries, caching).</li> <li>Investigate I/O subsystem if iowait high.</li> </ul>"},{"location":"2-project/reading_dashboards/#2-memory-ram","title":"2. Memory (RAM)","text":"<ul> <li> <p>What to look for:</p> </li> <li> <p>Total used vs total available.</p> </li> <li>Cache/buffers vs actual application usage.</li> <li>Swap usage.</li> <li> <p>Rules of thumb:</p> </li> <li> <p>If memory is \u201cfull\u201d but mostly cache \u2192 not a problem (Linux uses free RAM for caching).</p> </li> <li>If swap is active \u2192 real memory pressure.</li> <li> <p>What it means:</p> </li> <li> <p>High app usage \u2192 possible memory leak or undersized instance.</p> </li> <li>High swap usage \u2192 system thrashing, huge slowdown.</li> <li> <p>Actions:</p> </li> <li> <p>Restart leaking service.</p> </li> <li>Add more RAM.</li> <li>Optimize memory-heavy queries.</li> </ul>"},{"location":"2-project/reading_dashboards/#3-disk-storage","title":"3. Disk / Storage","text":"<ul> <li> <p>Metrics:</p> </li> <li> <p>Disk usage %.</p> </li> <li>IOPS (reads/writes per second).</li> <li>Latency (avg read/write ms).</li> <li> <p>Rules of thumb:</p> </li> <li> <p>80% disk full \u2192 plan cleanup/expansion.</p> </li> <li>Latency &gt;20ms on SSDs \u2192 bottleneck.</li> <li> <p>What it means:</p> </li> <li> <p>High latency + high iowait \u2192 storage bottleneck.</p> </li> <li>High disk usage \u2192 risk of system crash when full.</li> <li> <p>Actions:</p> </li> <li> <p>Clear logs / rotate.</p> </li> <li>Scale to larger disks.</li> <li>Use faster storage (NVMe, SSD).</li> </ul>"},{"location":"2-project/reading_dashboards/#4-network","title":"4. Network","text":"<ul> <li> <p>Metrics:</p> </li> <li> <p>Bandwidth in/out.</p> </li> <li>Packet drops/errors.</li> <li>Latency / RTT.</li> <li> <p>Rules of thumb:</p> </li> <li> <p>Bandwidth near link limit (e.g. 1Gbps NIC at 950Mbps) \u2192 saturation.</p> </li> <li>Packet drops/errors &gt;0 \u2192 network health issue.</li> <li> <p>What it means:</p> </li> <li> <p>High outbound traffic \u2192 app serving lots of data (normal or DDoS).</p> </li> <li>Latency spikes \u2192 congestion, routing problems.</li> <li> <p>Actions:</p> </li> <li> <p>Scale horizontally (more nodes).</p> </li> <li>Throttle heavy clients.</li> <li>Investigate load balancer.</li> </ul>"},{"location":"2-project/reading_dashboards/#5-containers-pods","title":"5. Containers / Pods","text":"<ul> <li> <p>Metrics:</p> </li> <li> <p>CPU &amp; memory per container.</p> </li> <li>Container restarts (counter).</li> <li>Pod status (running, crashloop).</li> <li> <p>Red flags:</p> </li> <li> <p>Containers restarting repeatedly \u2192 crashloop, misconfiguration.</p> </li> <li>CPU/memory throttling in Kubernetes.</li> <li> <p>What it means:</p> </li> <li> <p>Misconfigured resource limits.</p> </li> <li>App bugs (OOMKilled, segfaults).</li> <li> <p>Actions:</p> </li> <li> <p>Check logs for container crash cause.</p> </li> <li>Adjust requests/limits in K8s.</li> <li>Add replicas for load.</li> </ul>"},{"location":"2-project/reading_dashboards/#6-application-level","title":"6. Application Level","text":"<ul> <li> <p>Key metrics (the \u201cGolden Signals\u201d from Google SRE):</p> </li> <li> <p>Latency \u2192 how long requests take.</p> </li> <li>Traffic \u2192 requests per second.</li> <li>Errors \u2192 % of failed requests.</li> <li>Saturation \u2192 how \u201cfull\u201d the system is (queues, memory).</li> <li> <p>Interpretation:</p> </li> <li> <p>High latency + high errors \u2192 app/service bottleneck.</p> </li> <li>High latency + low CPU/memory \u2192 external dependency issue.</li> <li>High traffic spikes \u2192 expected? or DDoS?</li> <li> <p>Actions:</p> </li> <li> <p>Scale service horizontally.</p> </li> <li>Add caching layer.</li> <li>Optimize slow queries.</li> </ul>"},{"location":"2-project/reading_dashboards/#7-databases","title":"7. Databases","text":"<ul> <li> <p>Metrics:</p> </li> <li> <p>Query throughput (QPS).</p> </li> <li>Query latency.</li> <li>Locks, deadlocks.</li> <li>Buffer cache hit ratio.</li> <li> <p>Red flags:</p> </li> <li> <p>Slow queries \u2192 long latency spikes.</p> </li> <li>Lock waits \u2192 contention.</li> <li> <p>Actions:</p> </li> <li> <p>Add indexes.</p> </li> <li>Optimize queries.</li> <li>Add read replicas.</li> </ul>"},{"location":"2-project/reading_dashboards/#8-logs-events","title":"8. Logs &amp; Events","text":"<ul> <li>Dashboards often link to logs (via Loki, ELK, etc.).</li> <li>Use them to confirm the why behind metrics.</li> </ul>"},{"location":"2-project/reading_dashboards/#diagnosis-by-symptom","title":"Diagnosis by Symptom","text":"Symptom Likely Cause Where to Look High latency (slow site) CPU/memory saturated, DB slow, network congestion CPU, memory, DB dashboards Frequent 500 errors App crash, DB errors, bad config App logs, DB metrics Nodes going down Out of memory, disk full, network partition Node exporter, disk usage Container restarts Misconfig, OOMKilled, bad healthcheck Container/pod dashboards Traffic spike Legit user load vs DDoS Network + load balancer metrics Disk full alerts Logs, data growth, temp files Disk usage dashboard"},{"location":"2-project/reading_dashboards/#method-how-to-read-a-dashboard-like-a-pro","title":"Method: How to Read a Dashboard Like a Pro","text":"<ol> <li> <p>Start broad \u2192 drill down</p> </li> <li> <p>Begin with system overview (CPU/mem/disk).</p> </li> <li>Narrow to container/pod \u2192 app \u2192 DB.</li> <li> <p>Look for correlations</p> </li> <li> <p>High CPU at same time as latency spikes?</p> </li> <li>High iowait + disk latency \u2192 storage problem.</li> <li> <p>Timeline matters</p> </li> <li> <p>Spikes vs sustained trends tell different stories.</p> </li> <li> <p>Always check for \u201cinnocent victims\u201d</p> </li> <li> <p>If all pods restart at once \u2192 node issue, not app bug.</p> </li> </ol>"},{"location":"2-project/reading_dashboards/#world-class-habits","title":"World-Class Habits","text":"<ul> <li>Always correlate metrics + logs.</li> <li>Watch rate of change, not just absolute numbers (e.g., 10GB logs written/hour).</li> <li>Build mental models: Traffic \u2191 \u2192 CPU \u2191 \u2192 Latency \u2191 is expected. If not, dig deeper.</li> <li>Treat dashboards as hypothesis tools, not truth \u2014 confirm with logs, traces, configs.</li> </ul>"},{"location":"2-project/reading_dashboards/#tldr-cheatsheet","title":"TL;DR Cheatsheet","text":"<ul> <li>CPU &gt;90% sustained \u2192 bottleneck.</li> <li>Memory + swap high \u2192 thrashing.</li> <li>Disk &gt;80% full \u2192 expand.</li> <li>Disk latency &gt;20ms (SSD) \u2192 bottleneck.</li> <li>Network drops/errors \u2192 faulty NIC or congestion.</li> <li>Container restarts \u2192 crashloop (logs!).</li> <li>Latency + errors \u2192 app/db issue.</li> <li>Traffic spike \u2192 scale or DDoS check.</li> </ul>"},{"location":"2-project/reading_dashboards/#troubleshooting-flow-from-alert-root-cause","title":"Troubleshooting Flow \u2014 From Alert \u2192 Root Cause","text":"<pre><code>flowchart TD\n\nA[\"ALERT or User Complaint\"] --&gt; B{\"What is the symptom?\"}\n\nB --&gt;|Slow responses / High latency| C[\"Check Traffic Dashboard\"]\nB --&gt;|Errors or Crashes| D[\"Check Application Dashboard\"]\nB --&gt;|Node or Container down| E[\"Check Node/Pod Dashboard\"]\nB --&gt;|Disk Full| F[\"Check Disk Dashboard\"]\n\n%% Latency path\nC --&gt; C1{\"Is traffic normal?\"}\nC1 --&gt;|Yes| C2[\"Check CPU &amp; Memory\"]\nC1 --&gt;|No - Spike| C3[\"Check scaling\"]\n\nC2 --&gt;|CPU &gt; 90%| C4[\"Scale out or optimize app\"]\nC2 --&gt;|Memory/Swap high| C5[\"Possible leak or undersized - fix or resize\"]\nC2 --&gt;|Both OK| C6[\"Check Database latency\"]\n\nC3 --&gt;|Scaling works| C4\nC3 --&gt;|Scaling blocked| C7[\"Add caching/CDN, rate limiting\"]\n\nC6 --&gt;|DB slow| C8[\"Optimize queries, add replicas\"]\nC6 --&gt;|DB fine| C9[\"Check network\"]\n\nC9 --&gt;|Packet loss high| C10[\"Investigate NIC / load balancer\"]\nC9 --&gt;|Network fine| C11[\"Check external dependencies\"]\n\n%% Errors path\nD --&gt; D1{\"Error type?\"}\nD1 --&gt;|HTTP 500s| D2[\"Check logs - DB errors/config issues\"]\nD1 --&gt;|CrashLoop| D3[\"Check container memory/CPU limits\"]\nD1 --&gt;|OOMKilled| D4[\"Raise memory or fix leaks\"]\n\n%% Node/Pod path\nE --&gt; E1{\"Which failed?\"}\nE1 --&gt;|Node down| E2[\"Check disk, power, kernel logs\"]\nE1 --&gt;|Pod down| E3[\"Check healthchecks, events, logs\"]\n\n%% Disk path\nF --&gt; F1{\"Disk usage &gt; 80%?\"}\nF1 --&gt;|Yes - Logs| F2[\"Check log growth, tmp files\"]\nF1 --&gt;|Yes - Capacity| F3[\"Rotate/compress logs, expand disk\"]\nF1 --&gt;|No but I/O high| F4[\"Check IOPS &amp; latency\"]\n</code></pre>"},{"location":"2-project/reading_dashboards/#how-to-use-this-flow","title":"How to Use This Flow","text":"<ol> <li> <p>Start at the Symptom</p> </li> <li> <p>Alert: high latency, errors, disk full, pod restarts.</p> </li> <li> <p>User complaint: \u201csite is slow\u201d / \u201capp keeps crashing\u201d.</p> </li> <li> <p>Pick the Path</p> </li> <li> <p>Latency \u2192 traffic \u2192 CPU/mem \u2192 DB \u2192 network.</p> </li> <li>Errors \u2192 logs \u2192 DB/app configs \u2192 containers.</li> <li>Container down \u2192 check limits \u2192 healthchecks \u2192 logs.</li> <li> <p>Disk full \u2192 check log growth \u2192 cleanup \u2192 expand.</p> </li> <li> <p>Correlate Across Layers</p> </li> <li> <p>Example: high latency + high CPU = bottleneck.</p> </li> <li>Example: high latency + normal CPU/mem = likely DB or network.</li> </ol>"},{"location":"2-project/reading_dashboards/#key-dashboards-to-check-along-the-way","title":"Key Dashboards to Check Along the Way","text":"Step Dashboard / Metric What It Tells You Traffic spike Prometheus <code>http_requests_total</code> Is the load abnormal? CPU usage Node exporter <code>node_cpu_seconds_total</code> Is system CPU bound? Memory &amp; Swap Node exporter <code>node_memory_MemAvailable</code> Is system thrashing? Containers cAdvisor / K8s pod metrics Is a pod OOMKilled or throttled? DB latency postgres_exporter / mysql_exporter Are queries slow? Disk usage node_exporter filesystem Disk nearly full? Disk I/O node_disk_read/write_time Storage bottleneck? Network node_network_errors_total NIC drops/retransmits? Logs Loki / ELK / <code>docker logs</code> The \u201cwhy\u201d behind the metrics."},{"location":"2-project/reading_dashboards/#example-walkthroughs-with-flow","title":"Example Walkthroughs with Flow","text":""},{"location":"2-project/reading_dashboards/#example-1-slow-website","title":"Example 1: Slow Website","text":"<ul> <li>Latency up \u2192 traffic spike.</li> <li>CPU at 95% \u2192 bottleneck.</li> <li>Fix: scale replicas from 3 \u2192 6.</li> </ul>"},{"location":"2-project/reading_dashboards/#example-2-high-error-rate","title":"Example 2: High Error Rate","text":"<ul> <li>Errors are HTTP 500.</li> <li>Logs: \u201cDB connection failed\u201d.</li> <li>DB connections maxed.</li> <li>Fix: increase pool size, optimize queries.</li> </ul>"},{"location":"2-project/reading_dashboards/#example-3-container-restarting","title":"Example 3: Container Restarting","text":"<ul> <li>Pod in CrashLoop.</li> <li>Container OOMKilled.</li> <li>Fix: raise memory limit, tune heap size.</li> </ul>"},{"location":"2-project/reading_dashboards/#example-4-disk-full","title":"Example 4: Disk Full","text":"<ul> <li>Disk usage 95%.</li> <li><code>/var/log</code> growing fast.</li> <li>Fix: rotate logs, expand disk.</li> </ul>"},{"location":"2-project/reading_dashboards/#devops-mindset","title":"DevOps Mindset","text":"<ul> <li>Always think in layers:   User \u2192 Load Balancer \u2192 App \u2192 DB \u2192 OS \u2192 Hardware/Network.</li> <li>Use dashboards to narrow down which layer is misbehaving.</li> <li>Confirm with logs to know why.</li> <li>Fix immediate issue \u2192 plan long-term solution.</li> </ul>"},{"location":"2-project/reading_dashboards/#troubleshooting-examples-with-dashboards","title":"Troubleshooting Examples with Dashboards","text":""},{"location":"2-project/reading_dashboards/#scenario-1-website-is-slow-high-latency","title":"Scenario 1: Website is Slow (High Latency)","text":""},{"location":"2-project/reading_dashboards/#symptom","title":"Symptom:","text":"<ul> <li>Users report: \u201cSite feels sluggish\u201d.</li> <li>Grafana shows latency rising above 2s.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-1-check-traffic","title":"Step 1: Check Traffic","text":"<ul> <li>Dashboard: Request rate (Prometheus <code>http_requests_total</code>).</li> <li>Observation: Traffic is 2\u00d7 higher than normal.</li> <li>\ud83d\udc49 Spike in demand.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-2-check-cpu","title":"Step 2: Check CPU","text":"<ul> <li>Dashboard: Node exporter CPU usage.</li> <li>Observation: CPU at 95%.</li> <li>\ud83d\udc49 Server is CPU-bound.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-3-correlate-with-app","title":"Step 3: Correlate with App","text":"<ul> <li>Dashboard: Container resource usage (cAdvisor).</li> <li>Observation: The web app container is consuming most CPU.</li> </ul>"},{"location":"2-project/reading_dashboards/#likely-cause","title":"Likely Cause:","text":"<ul> <li>Increased load \u2192 CPU saturated.</li> </ul>"},{"location":"2-project/reading_dashboards/#fix","title":"Fix:","text":"<ul> <li>Scale replicas from 3 \u2192 6.</li> <li>Add caching (e.g., Cloudflare / Redis).</li> </ul>"},{"location":"2-project/reading_dashboards/#scenario-2-high-error-rate-http-500s","title":"Scenario 2: High Error Rate (HTTP 500s)","text":""},{"location":"2-project/reading_dashboards/#symptom_1","title":"Symptom:","text":"<ul> <li>Alert: \u201c5% of requests failing with 500 errors\u201d.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-1-check-application-logs","title":"Step 1: Check Application Logs","text":"<ul> <li>Dashboard link: Loki/ELK.</li> <li>Observation: \u201cDB connection failed: too many connections\u201d.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-2-check-database-metrics","title":"Step 2: Check Database Metrics","text":"<ul> <li>Dashboard: PostgreSQL exporter.</li> <li>Observation: Connection count at max (100).</li> </ul>"},{"location":"2-project/reading_dashboards/#step-3-check-query-latency","title":"Step 3: Check Query Latency","text":"<ul> <li>Observation: Queries piling up, high wait time.</li> </ul>"},{"location":"2-project/reading_dashboards/#likely-cause_1","title":"Likely Cause:","text":"<ul> <li>DB connection pool exhausted.</li> </ul>"},{"location":"2-project/reading_dashboards/#fix_1","title":"Fix:","text":"<ul> <li>Increase DB connection pool size.</li> <li>Optimize slow queries.</li> <li>Add a DB read replica if traffic keeps growing.</li> </ul>"},{"location":"2-project/reading_dashboards/#scenario-3-container-keeps-restarting","title":"Scenario 3: Container Keeps Restarting","text":""},{"location":"2-project/reading_dashboards/#symptom_2","title":"Symptom:","text":"<ul> <li>Alert: \u201cApp container restarting repeatedly (CrashLoopBackOff)\u201d.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-1-check-container-restarts","title":"Step 1: Check Container Restarts","text":"<ul> <li>Dashboard: cAdvisor / Kubernetes pod metrics.</li> <li>Observation: Container restarted 12 times in 5 minutes.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-2-check-memory-usage","title":"Step 2: Check Memory Usage","text":"<ul> <li>Observation: Container hits memory limit (512MB), then OOMKilled.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-3-check-logs","title":"Step 3: Check Logs","text":"<ul> <li>Observation: Java app error: \u201cOutOfMemoryError: Java heap space\u201d.</li> </ul>"},{"location":"2-project/reading_dashboards/#likely-cause_2","title":"Likely Cause:","text":"<ul> <li>App exceeds container memory limits.</li> </ul>"},{"location":"2-project/reading_dashboards/#fix_2","title":"Fix:","text":"<ul> <li>Increase memory limit to 1GB.</li> <li>Tune JVM heap settings.</li> <li>Monitor for leaks.</li> </ul>"},{"location":"2-project/reading_dashboards/#scenario-4-disk-full","title":"Scenario 4: Disk Full","text":""},{"location":"2-project/reading_dashboards/#symptom_3","title":"Symptom:","text":"<ul> <li>Alert: \u201cDisk usage &gt; 90%\u201d.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-1-check-disk-usage","title":"Step 1: Check Disk Usage","text":"<ul> <li>Dashboard: Node exporter filesystem metrics.</li> <li>Observation: <code>/var/log</code> partition at 95%.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-2-drill-into-log-volume","title":"Step 2: Drill Into Log Volume","text":"<ul> <li>Observation: App logs growing at 1GB/hour.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-3-correlate-with-traffic","title":"Step 3: Correlate With Traffic","text":"<ul> <li>Observation: Error logs spiking with traffic surge.</li> </ul>"},{"location":"2-project/reading_dashboards/#likely-cause_3","title":"Likely Cause:","text":"<ul> <li>App spamming logs due to repeated errors.</li> </ul>"},{"location":"2-project/reading_dashboards/#fix_3","title":"Fix:","text":"<ul> <li>Fix root cause of error.</li> <li>Rotate/compress logs.</li> <li>Increase disk size if needed.</li> </ul>"},{"location":"2-project/reading_dashboards/#scenario-5-network-latency-spikes","title":"Scenario 5: Network Latency Spikes","text":""},{"location":"2-project/reading_dashboards/#symptom_4","title":"Symptom:","text":"<ul> <li>Alert: \u201cP95 latency &gt; 500ms\u201d.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-1-check-network-dashboard","title":"Step 1: Check Network Dashboard","text":"<ul> <li>Observation: High packet retransmits on one node.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-2-check-node-health","title":"Step 2: Check Node Health","text":"<ul> <li>Observation: NIC errors increasing.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-3-correlate-with-service","title":"Step 3: Correlate With Service","text":"<ul> <li>Observation: Only services on node-2 affected.</li> </ul>"},{"location":"2-project/reading_dashboards/#likely-cause_4","title":"Likely Cause:","text":"<ul> <li>Faulty NIC or driver issue on node-2.</li> </ul>"},{"location":"2-project/reading_dashboards/#fix_4","title":"Fix:","text":"<ul> <li>Drain node-2 (<code>kubectl cordon node-2</code>).</li> <li>Replace or troubleshoot hardware.</li> </ul>"},{"location":"2-project/reading_dashboards/#scenario-6-prometheus-missing-metrics","title":"Scenario 6: Prometheus Missing Metrics","text":""},{"location":"2-project/reading_dashboards/#symptom_5","title":"Symptom:","text":"<ul> <li>Dashboard panel blank.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-1-check-prometheus-targets","title":"Step 1: Check Prometheus Targets","text":"<ul> <li>Dashboard: Prometheus <code>/targets</code> UI.</li> <li>Observation: Target <code>node-exporter:9100</code> is <code>DOWN</code>.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-2-check-service","title":"Step 2: Check Service","text":"<ul> <li>Observation: node-exporter container stopped.</li> </ul>"},{"location":"2-project/reading_dashboards/#step-3-check-logs_1","title":"Step 3: Check Logs","text":"<ul> <li>Observation: Error binding to port <code>9100</code>.</li> </ul>"},{"location":"2-project/reading_dashboards/#likely-cause_5","title":"Likely Cause:","text":"<ul> <li>Port conflict or container crash.</li> </ul>"},{"location":"2-project/reading_dashboards/#fix_5","title":"Fix:","text":"<ul> <li>Restart node-exporter.</li> <li>Ensure no other process using 9100.</li> </ul>"},{"location":"2-project/reading_dashboards/#quick-troubleshooting-playbook","title":"Quick Troubleshooting Playbook","text":"Symptom Where to Look Common Causes Actions High latency CPU, DB latency CPU saturation, slow queries, network congestion Scale out, add cache, optimize queries High error rate Logs, app metrics DB pool exhausted, app crash, misconfig Fix DB, check app health Container restarts Container metrics, logs OOMKilled, crashloop, bad healthcheck Increase limits, debug app Disk full Node exporter disk Log growth, data not rotated Cleanup, rotate logs Network drops NIC stats, node dashboard Faulty NIC, congestion Replace NIC, move workload Missing metrics Prometheus targets Exporter down, scrape failure Restart exporter, fix config <p>With this playbook:</p> <ul> <li>Start at symptom (latency, errors, restarts).</li> <li>Drill into dashboards (CPU/mem/disk/net/app).</li> <li>Correlate across layers (infra \u2192 container \u2192 app \u2192 DB).</li> <li>Confirm with logs.</li> <li>Apply fix or scale.</li> </ul>"},{"location":"2-project/setup/","title":"Our Setup","text":"<p>By default kubernetes doesn't automatically ship cluster level metrics (deployments, pods, nodes, jobs) so we will have to deploy a kube-state-metrics container, which Exposes the state of Kubernetes objects (deployments, pods, nodes, jobs).</p> <p>Every node should run a node_exporter as a daemonSet (pod that runs on every node in the cluster), such taht we won't need to remember to deploy one whenever we add a node to the cluster.</p> <p>We will deploy Prometheus using HELM(a package manager for K8s) to make the process repeatable. The Kube-Prometheus-Stack HELM chart will be used. It makes use of the Prometheus Operator. A K8s operator is an application-specific controller that extends the K8s API to create/configure/manage instances of complex applications (the complete lifecycle for Prometheus in our case). </p> <p>The prometheus operator has several custom resources to aid the deployment and management of a Prometheues instance. (See Image below)</p> <p></p> <p>This makes life a lot easier as we will have a higher level abstraction of the underlying resources.</p>"},{"location":"2-project/setup/#add-the-chart","title":"Add the Chart","text":"<pre><code>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\n\nhelm repo update\n\nhelm install prometheus prometheus-community/kube-prometheus-stack\n#                 ^\n#                 |\n#    this name can be anything\n</code></pre> <p>We can edit the default configuratioin of the chart by editing the values:</p> <pre><code>helm show values prometheus-community/kube-prometheus-stack &gt; prometheus-helm-values.yaml\n# and after editing a value:\nhelm install prometheus prometheus-community/kube-prometheus-stack -f prometheus-helm-values.yaml\n</code></pre> <p>By default prometheus deploys the following:</p> <pre><code>NAME                                                         READY   STATUS    RESTARTS   AGE\npod/alertmanager-prometheus-kube-prometheus-alertmanager-0   2/2     Running   0          14m\npod/prometheus-grafana-674cf8cb44-l8479                      3/3     Running   0          14m\npod/prometheus-kube-prometheus-operator-6694cc948f-7xlh8     1/1     Running   0          14m\npod/prometheus-kube-state-metrics-7c5fb9d798-82n44           1/1     Running   0          14m\npod/prometheus-prometheus-kube-prometheus-prometheus-0       2/2     Running   0          14m\npod/prometheus-prometheus-node-exporter-zck8r                1/1     Running   0          14m\n\nNAME                                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\nservice/alertmanager-operated                     ClusterIP   None            &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP   14m\nservice/prometheus-grafana                        ClusterIP   10.96.2.11      &lt;none&gt;        80/TCP                       14m\nservice/prometheus-kube-prometheus-alertmanager   ClusterIP   10.96.226.179   &lt;none&gt;        9093/TCP,8080/TCP            14m\nservice/prometheus-kube-prometheus-operator       ClusterIP   10.96.72.246    &lt;none&gt;        443/TCP                      14m\nservice/prometheus-kube-prometheus-prometheus     ClusterIP   10.96.37.230    &lt;none&gt;        9090/TCP,8080/TCP            14m\nservice/prometheus-kube-state-metrics             ClusterIP   10.96.112.1     &lt;none&gt;        8080/TCP                     14m\nservice/prometheus-operated                       ClusterIP   None            &lt;none&gt;        9090/TCP                     14m\nservice/prometheus-prometheus-node-exporter       ClusterIP   10.96.92.210    &lt;none&gt;        9100/TCP                     14m\n\nNAME                                                 DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\ndaemonset.apps/prometheus-prometheus-node-exporter   1         1         1       1            1           kubernetes.io/os=linux   14m\n\nNAME                                                  READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/prometheus-grafana                    1/1     1            1           14m\ndeployment.apps/prometheus-kube-prometheus-operator   1/1     1            1           14m\ndeployment.apps/prometheus-kube-state-metrics         1/1     1            1           14m\n\nNAME                                                             DESIRED   CURRENT   READY   AGE\nreplicaset.apps/prometheus-grafana-674cf8cb44                    1         1         1       14m\nreplicaset.apps/prometheus-kube-prometheus-operator-6694cc948f   1         1         1       14m\nreplicaset.apps/prometheus-kube-state-metrics-7c5fb9d798         1         1         1       14m\n\nNAME                                                                    READY   AGE\nstatefulset.apps/alertmanager-prometheus-kube-prometheus-alertmanager   1/1     14m\nstatefulset.apps/prometheus-prometheus-kube-prometheus-prometheus       1/1     14m\n</code></pre> <p>Take note of a few things:</p> <ul> <li>All Services are of type ClusterIP.</li> <li><code>deployment.apps/prometheus-grafana</code> - The chart also spins up a preconfigured Grafana instance.</li> <li><code>deployment.apps/prometheus-kube-prometheus-operator</code> is the Prometheus operator we talked about.</li> <li><code>deployment.apps/prometheus-kube-state-metrics</code> exposes object metrics (nodes, pods, deployments, jobs).</li> <li><code>daemonset.apps/prometheus-prometheus-node-exporter</code> makes sure we have a node exporter on all modes.</li> <li><code>pod/prometheus-prometheus-node-exporter-zck8r</code> will be one per every node (we only have one node but if we had another we would have another e.g <code>pod/prometheus-prometheus-node-exporter-xntb2</code> )</li> </ul>"},{"location":"2-project/setup/#connecting-to-prometheus","title":"Connecting to Prometheus","text":"<p>We could setup an Ingress to access the prometheus service, but in this demo we will make use of port forwarding.</p> <p><code>kubectl port-forward</code> works for both Pods and Services</p> <ul> <li>Pod:   You can forward directly to a Pod by its name:</li> </ul> <pre><code>kubectl port-forward pod/my-pod 8080:80\n</code></pre> <p>This connects your local port <code>8080</code> to port <code>80</code> inside the Pod.</p> <ul> <li>Service:   You can also forward to a Service:</li> </ul> <pre><code>kubectl port-forward svc/my-service 8080:80\n</code></pre> <p>In this case, <code>kubectl</code> resolves the Service to one of its backing Pods and forwards traffic to it. (It doesn\u2019t load-balance across Pods \u2014 just picks one.)</p> <p>So:</p> <ul> <li>Pod = direct connection to that Pod.</li> <li>Service = convenience, so you don\u2019t need to look up Pod names.</li> </ul> <p>So we run:</p> <pre><code>kubectl get service\n# then port forward the Prometheus service\nkubectl port-forward svc/prometheus-kube-prometheus-prometheus 9090\n</code></pre>"},{"location":"2-project/setup/#deploying-the-application-instance","title":"Deploying the application instance","text":"<p>We placed our <code>demo_app_deployment.yaml</code> and <code>demo_app_svc.yaml</code> in the <code>k8s</code> folder then ran:</p> <pre><code>kubectl create -f k8s/ # creates 2 pods and a service\n# Followed up with:\ntask status\n</code></pre> <p>Nice, the app is now running in our cluster.</p> <p>We will have to setup additional prometheus configs so that the app can be scrapped by prometheus.</p> <p>The recommended way to set up monitoring in this stack, is to make use of Service Monitors.</p>"},{"location":"2-project/setup/#setup-app-metrics-scrapping","title":"Setup App Metrics Scrapping","text":"<p>A Service Monitor defines a set of targets for prometheus to monitor and scrape.</p> <p>That way we avoid touching the default configs directly, instead we will be using the CRD to append new targets for Prometheus to scrape.</p> <p>A service monitor points to a Service.</p> <p> </p> <p>The <code>service-monitor.yaml</code> file is added alongside the app deployment files in the <code>k8s/</code> folder.</p> <pre><code>task apply-app\n# then\nkubectl get servicemonitor # to confirm if our service monitor is deployed\n# output:\nNAME                                                 AGE\nprometheus-demo-app-svc-monitor                      2m13s\n</code></pre> <p>Also confirm in the Prometheus web app at <code>/targets</code>:</p> <p></p> <p>You can also query <code>{job=\"prometheus-demo-app-svc\"}</code>:</p> <p></p>"},{"location":"2-project/setup/#adding-rules","title":"Adding Rules","text":"<p>Prometheus also has a CRD for handling rules named <code>prometheusrule</code>.</p> <p></p> <p></p> <p>The <code>prometheusrules.yaml</code> file is added alongside the app deployment files in the <code>k8s/</code> folder.</p> <pre><code>task apply-app\n# then\nkubectl get prometheusrule # to confirm if our service monitor is deployed\n# output:\nNAME                                                              AGE\nprometheus-demo-app-rules                                         60s\n</code></pre> <p>Also confirm in the Prometheus web app at <code>/rules</code>:</p> <p></p>"},{"location":"2-project/setup/#adding-alert-manager-rules","title":"Adding Alert Manager Rules","text":"<p>First we need to note an important point when it comes to specifying custom values.yaml</p> <p>Helm merges your custom <code>values.yaml</code> with the chart\u2019s default values. It uses a deep merge, so you must preserve the full key path when overriding values.  </p> <ul> <li>If you only define part of the path, Helm will ignore it.  </li> <li>You must follow the parent hierarchy exactly as defined in the chart\u2019s <code>values.yaml</code>.  </li> <li>Always check the chart\u2019s defaults with:  </li> </ul> <pre><code>  helm show values &lt;chart&gt;\n</code></pre> <p>If you try to set this at the root:</p> <pre><code>alertmanagerConfigSelector:\n  matchLabels:\n    resource: prometheus\n</code></pre> <p>\u2026it will fail, because <code>alertmanagerConfigSelector</code> is not a root key.</p> <p>In the kube-prometheus-stack chart, the correct path is under <code>prometheus.prometheusSpec</code>:</p> <pre><code>prometheus:\n  prometheusSpec:\n    alertmanagerConfigSelector:\n      matchLabels:\n        resource: prometheus\n</code></pre> <ul> <li>Helm only overrides keys at the correct hierarchy.</li> <li>Wrong placement = no effect.</li> <li>Always trace the full path from the chart\u2019s default <code>values.yaml</code>.</li> </ul>"},{"location":"2-project/setup/#continuing-with-our-setup","title":"Continuing with our setup","text":"<p>Prometheus also has a CRD for handling alert manager rules named <code>AlertmangerConfig</code>.</p> <p></p> <p></p> <p></p> <p>By default this selector is not in prometheus' <code>values.yaml</code> so we have to add it.</p> <pre><code>task prom-helm-values\n</code></pre> <p>Then search for <code>alertmanagerConfigSelector</code>, copy the snippet and save in a custom values file as <code>k8s/prometheus-helm-values.yaml</code>:</p> <pre><code>alertmanagerConfigSelector:\n  matchLabels:\n    resource: prometheus\n</code></pre> <p>Then apply:</p> <pre><code>task helm-upgrade-prom\n</code></pre> <p></p> <p>The <code>alertmanager-config.yaml</code> file is added alongside the app deployment files in the <code>k8s/</code> folder.</p> <pre><code>task apply-app\n\n# then\nkubectl get alertmanagers.monitoring.coreos.com -o yaml # to confirm if our service monitor is deployed\n\n# output:\n# serach for:\n...\n    alertmanagerConfigSelector:\n      matchLabels:\n        resource: prometheus\n...\n\n# and\nkubectl get alertmanagerconfig\n\n# output:\nNAME                               AGE\nprometheus-demo-app-alert-config   7m59s\n\n# then:\ntask port-fwd-alertm\n# and visit /localhost:9093\n</code></pre> <p>Tip</p> <p>When port fowarding, the port number is always the one exposed by the service or Pod or you can specify as <code>HOST:SVC/POD</code></p> <p>Also confirm in the Prometheus web app at <code>/rules</code>:</p> <p></p>"},{"location":"2-project/setup/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>The Helm chart already has pre-configured dashboards.</p> <p>We port forward the Grafana UI:</p> <pre><code>task port-fwd-graf\n</code></pre> <p>Tip</p> <p>When port fowarding, the port number is always the one exposed by the service or Pod or you can specify as <code>HOST:SVC/POD</code></p> <p>We then add other dashboards namely: <code>15661</code>.</p> <p></p> <p>We can also add instrumentation for our app and add to prometheus scrape config and also add relevant dashboards.</p> <p>This confirms our setup is complete !</p> <pre><code>&gt; task status\ntask: [status] kubectl get all -n k8s-monitoring-ns\n[status] NAME                                                         READY   STATUS    RESTARTS      AGE\n[status] pod/alertmanager-prometheus-kube-prometheus-alertmanager-0   2/2     Running   2 (58m ago)   116m\n[status] pod/prometheus-demo-app-794dc7c997-bz9fp                     1/1     Running   1 (58m ago)   107m\n[status] pod/prometheus-demo-app-794dc7c997-g4275                     1/1     Running   1 (58m ago)   107m\n[status] pod/prometheus-grafana-674cf8cb44-v8vlb                      3/3     Running   3 (58m ago)   117m\n[status] pod/prometheus-kube-prometheus-operator-7984bfd549-g9gnx     1/1     Running   2 (57m ago)   117m\n[status] pod/prometheus-kube-state-metrics-7c5fb9d798-xwdpq           1/1     Running   2 (57m ago)   117m\n[status] pod/prometheus-prometheus-kube-prometheus-prometheus-0       2/2     Running   2 (58m ago)   116m\n[status] pod/prometheus-prometheus-node-exporter-scsd8                1/1     Running   1 (58m ago)   117m\n[status]\n[status] NAME                                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\n[status] service/alertmanager-operated                     ClusterIP   None            &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP   116m\n[status] service/prometheus-demo-app-svc                   ClusterIP   10.96.139.140   &lt;none&gt;        3000/TCP                     107m\n[status] service/prometheus-grafana                        ClusterIP   10.96.199.255   &lt;none&gt;        80/TCP                       117m\n[status] service/prometheus-kube-prometheus-alertmanager   ClusterIP   10.96.210.241   &lt;none&gt;        9093/TCP,8080/TCP            117m\n[status] service/prometheus-kube-prometheus-operator       ClusterIP   10.96.75.79     &lt;none&gt;        443/TCP                      117m\n[status] service/prometheus-kube-prometheus-prometheus     ClusterIP   10.96.219.164   &lt;none&gt;        9090/TCP,8080/TCP            117m\n[status] service/prometheus-kube-state-metrics             ClusterIP   10.96.12.61     &lt;none&gt;        8080/TCP                     117m\n[status] service/prometheus-operated                       ClusterIP   None            &lt;none&gt;        9090/TCP                     116m\n[status] service/prometheus-prometheus-node-exporter       ClusterIP   10.96.96.156    &lt;none&gt;        9100/TCP                     117m\n[status]\n[status] NAME                                                 DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\n[status] daemonset.apps/prometheus-prometheus-node-exporter   1         1         1       1            1           kubernetes.io/os=linux   117m\n[status]\n[status] NAME                                                  READY   UP-TO-DATE   AVAILABLE   AGE\n[status] deployment.apps/prometheus-demo-app                   2/2     2            2           107m\n[status] deployment.apps/prometheus-grafana                    1/1     1            1           117m\n[status] deployment.apps/prometheus-kube-prometheus-operator   1/1     1            1           117m\n[status] deployment.apps/prometheus-kube-state-metrics         1/1     1            1           117m\n[status]\n[status] NAME                                                             DESIRED   CURRENT   READY   AGE\n[status] replicaset.apps/prometheus-demo-app-794dc7c997                   2         2         2       107m\n[status] replicaset.apps/prometheus-grafana-674cf8cb44                    1         1         1       117m\n[status] replicaset.apps/prometheus-kube-prometheus-operator-7984bfd549   1         1         1       117m\n[status] replicaset.apps/prometheus-kube-state-metrics-7c5fb9d798         1         1         1       117m\n[status]\n[status] NAME                                                                    READY   AGE\n[status] statefulset.apps/alertmanager-prometheus-kube-prometheus-alertmanager   1/1     116m\n[status] statefulset.apps/prometheus-prometheus-kube-prometheus-prometheus       1/1     116m\n</code></pre>"},{"location":"2-project/setup/#setting-up-alertmanager-with-slack","title":"Setting up AlertManager with Slack","text":"<p>First head to api.slack.com/apps</p> <p>Add a new app named <code>alert-manager</code> and add it to a workspace.</p> <p>We already have a workspace named devopssean. </p> <p>in the features, enable an Incoming Webhook and select the channel to post to. In our case we have the alert-manager channel.</p> <p>Info</p> <p>Incoming webhooks are a simple way to post messages from external sources into Slack. They make use of normal HTTP requests with a JSON payload, which includes the message and a few other optional details. You can include message attachments to display richly-formatted messages.</p> <p>Adding incoming webhooks requires a bot user. If your app doesn't have a bot user, slack will add one for you.</p> <p>Each time your app is installed, a new Webhook URL will be generated.</p> <p>If you want to test intergration run the curl command in the UI inside your terminal e.g:</p> <pre><code>curl -X POST -H 'Content-type: application/json' --data '{\"text\":\"Alert Manager Curl Test!\"}' &lt;slack-channel-webhook&gt;\n</code></pre> <p>Take note of the webhook URL.</p> <p>We add that to the alertmanager-config.yaml under a slackConfig receiver, as raw string or more preferrably as a Secret.</p> <p>In this demo we use a plain string secret.</p> <p>To test the alert, shutdown the app instance by either deleting the whole thing or scaling the app's deployment down to 0 pods and then check the slack channel.</p> <p></p>"},{"location":"2-project/setup/#set-up-loki","title":"Set up Loki","text":"<p>We wan't Logs for our application to also be shown in Grafana dashboards.</p> <p>It will make it easier to diagonise spikes and dips in resource usage metrics.</p> <p>Loki is part of the Grafana Helm chart. </p> <pre><code>helm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\n</code></pre> <p>We then save a custom values to the <code>k8s/values</code> directory.</p> <p>We only specify the sections we need to change.</p> <ul> <li>We chose <code>deployment: SingleBinary</code> because it deploys every single component that loki needs as a single binary. This deploymentonly allows a loki to process a few gigabytes of logs a day whilst others result in Terrabytes albeit with a much more complex deployment. The deployyment mode should always match the environment that you the cluster operates.</li> <li>Write, read and backend replicas are set to 0 as we only have a single deployment</li> <li>Storage is set to filesystem instead of a cloud storage option.</li> <li>Disabled caching and helm testing</li> </ul> <pre><code>kubens k8s-monitoring-ns\nhelm install loki grafana/loki -f k8s/values/graf-helm-values.yaml\n</code></pre> <p>Info</p> <p>During  <code>helm install</code>, it's important to always state the version of helm chart that you are using by making use of the <code>--version</code> flag. A repeatable way is to use a tool like <code>Terraform</code></p> <p>These are the current versions of the charts we used in this tutorial:</p> <pre><code>NAME           CHART                            APP VERSION\nloki           loki-6.41.1                      3.5.5\nprometheus     kube-prometheus-stack-77.11.1    v0.85.0\n</code></pre> <p>We then include a grafana section in the prometheus values file in the <code>k8s/values</code> directory, to include an additional data source named loki.</p> <p>We apply the changes.</p> <pre><code>task helm-upgrade-all\n</code></pre> <p>Inside the grafana UI we head to the data sources section to confirm that loki is there.</p> <p></p>"},{"location":"2-project/setup/#generating-logs","title":"Generating Logs","text":"<p>We can make use of a fake log generator container <code>mingrammer/flog</code>.</p> <p>In the repository we also have a Application deployment in <code>k8s/fake-logs.yaml</code> coupled with the fake log generator outputting the logs to a PVC, a promtail log collector mounted to the same PVC and a configMap to then send those over to loki.</p> <p>For testing on a single-node cluster, this manifest is okay. It will:</p> <ul> <li>Generate fake JSON logs into a shared PVC.</li> <li>Have Promtail tail the log file, parse JSON, and push entries to Loki.</li> <li>Attach <code>http_method</code> and <code>http_status</code> as labels.</li> <li>Use an ephemeral <code>emptyDir</code> for positions, good enough for short tests.</li> </ul> <p>Caveats you accept when testing this way:</p> <ul> <li>Not production-ready: multiple replicas or nodes will break because of the RWO PVC.</li> <li>Data replay: if Promtail restarts, it replays logs since positions are not persisted to durable storage.</li> <li>Log source unrealistic: real apps log to <code>stdout</code>, not a shared file.</li> <li>Performance: flog will generate constant noise. That\u2019s fine for load testing Loki, not for validating app-level observability.</li> </ul> <p>So: for verifying that your stack is wired correctly (Promtail \u2192 Loki \u2192 Grafana queries), this setup is good enough.</p>"},{"location":"2-project/setup/#visualising-in-grafana","title":"Visualising in Grafana","text":"<p>We then import the <code>grafana/dashboards/fake-logs-dashboard.json</code> file to visualise in grafana.</p> <p></p> <p>And with that done, so is our setup !</p>"},{"location":"2-project/setup/#some-caveats","title":"Some Caveats","text":"<p>It is not production-ready by default. The stack (kube-prometheus-stack, Loki, Grafana, Alertmanager, OpenTelemetry) provides the core observability components, but production readiness depends on how it is configured, secured, and operated.</p>"},{"location":"2-project/setup/#gaps-and-risks","title":"Gaps and risks:","text":"<ol> <li> <p>Persistence</p> <ul> <li>Default Helm charts often use emptyDir volumes. Data loss occurs on pod rescheduling.</li> <li>Loki, Prometheus, and Alertmanager require durable storage (PVCs on reliable storage classes).</li> </ul> </li> <li> <p>High availability (HA)</p> <ul> <li>kube-prometheus-stack deploys single replicas by default. Prometheus, Alertmanager, and Loki should run in HA mode with replication and sharding.</li> </ul> </li> <li> <p>Scaling</p> <ul> <li>Loki requires proper deployment mode (distributor, ingester, querier, etc.) for large clusters. Monolithic mode will not handle production workloads.</li> <li>Prometheus requires federation or Cortex/Thanos for horizontal scalability.</li> </ul> </li> <li> <p>Security</p> <ul> <li>RBAC must be minimal and auditable.</li> <li>Grafana and Alertmanager must not expose admin endpoints publicly without authentication and TLS.</li> <li>Secrets in Helm values should not be stored in plaintext.</li> </ul> </li> <li> <p>Resource limits</p> <ul> <li>Default charts lack tuned CPU/memory requests and limits. These must be set based on workload.</li> </ul> </li> <li> <p>Backup and retention</p> <ul> <li>No backup strategy for Prometheus TSDB, Loki indexes, or Alertmanager silences.</li> <li>Retention periods must be tuned for cost and compliance.</li> </ul> </li> <li> <p>Networking</p> <ul> <li>Ingress configuration requires TLS termination and WAF/firewall integration.</li> <li>Multi-tenant isolation may be required if different teams access Grafana or Loki.</li> </ul> </li> <li> <p>Alerting pipeline</p> <ul> <li>Alertmanager configuration must be HA and integrated with real notification systems (PagerDuty, OpsGenie, email, Slack).</li> <li>Silencing, inhibition, and deduplication must be tuned.</li> </ul> </li> <li> <p>OpenTelemetry integration</p> <ul> <li>Only provides traces/metrics/logs pipelines. Backend storage (Tempo, Jaeger, or vendor) is required.</li> <li>Exporters must be configured per language/runtime.</li> </ul> </li> <li> <p>Operations</p> <ul> <li>Helm upgrades can break CRDs. Proper GitOps or CI/CD integration is required.</li> <li>Dashboards and alerts must be version-controlled, not edited manually in Grafana.</li> </ul> </li> </ol>"},{"location":"2-project/setup/#minimal-production-ready-setup-requires","title":"Minimal production-ready setup requires:","text":"<ul> <li>HA Prometheus, Loki, and Alertmanager.</li> <li>Persistent storage with backups.</li> <li>TLS, RBAC, and external auth (OIDC) for Grafana.</li> <li>Proper retention, capacity planning, and scaling.</li> <li>Automated upgrades via GitOps (e.g., ArgoCD, Flux).</li> <li>Centralised alert routing with redundancy.</li> <li>Integration with a tracing backend (Tempo or Jaeger) if OpenTelemetry is used fully.</li> </ul>"},{"location":"2-project/setup/#using-grafana-cloud","title":"Using Grafana Cloud","text":""},{"location":"2-project/setup/#effect-on-our-proposed-stack","title":"Effect on our proposed stack","text":"<ol> <li> <p>Prometheus / kube-prometheus-stack</p> <ul> <li>You no longer run Prometheus in-cluster for long-term storage.</li> <li>Instead, you deploy the Grafana Agent (or Prometheus remote-write) in your cluster. It scrapes Kubernetes metrics and forwards them to Grafana Cloud\u2019s Mimir backend.</li> <li>kube-prometheus-stack is unnecessary except if you still want local alerting or dashboards inside the cluster.</li> </ul> </li> <li> <p>Loki</p> <ul> <li>You do not run Loki in-cluster unless you want a local buffer.</li> <li>Logs are shipped with Grafana Agent, Fluent Bit, or Promtail to Grafana Cloud Loki.</li> </ul> </li> <li> <p>Grafana</p> <ul> <li>You do not deploy Grafana in-cluster. Dashboards are hosted in Grafana Cloud.</li> <li>You can still federate multiple data sources (cloud Loki, cloud Prometheus, external APIs).</li> </ul> </li> <li> <p>Alertmanager</p> <ul> <li>You do not run Alertmanager. Alert routing is handled in Grafana Cloud\u2019s alerting service.</li> <li>You must re-implement silences, inhibition, and notification channels in Grafana Cloud.</li> </ul> </li> <li> <p>OpenTelemetry</p> <ul> <li>You deploy the OpenTelemetry Collector in your cluster.</li> <li>The collector exports traces and metrics directly to Grafana Cloud Tempo (for traces) and Mimir (for metrics).</li> <li>No need to deploy Tempo or Jaeger locally.</li> </ul> </li> </ol>"},{"location":"2-project/setup/#setup-steps","title":"Setup steps","text":"<ol> <li> <p>Sign up and create a Grafana Cloud stack </p> <ul> <li>Provision an account with metrics, logs, and traces enabled.  </li> <li>Obtain API keys (for metrics, logs, traces).  </li> </ul> </li> <li> <p>Deploy Grafana Agent in Kubernetes </p> <ul> <li>Install via Helm or YAML manifests.  </li> <li>Configure it to:  <ul> <li>Scrape kubelet, kube-state-metrics, node exporter.  </li> <li>Remote-write to Grafana Cloud Prometheus endpoint.  </li> <li>Forward logs via Loki endpoint.  </li> <li>Ship traces via Tempo endpoint (optionally through OTLP).  </li> </ul> </li> </ul> </li> <li> <p>Deploy OpenTelemetry Collector </p> <ul> <li>Configure it to receive OTLP (from application SDKs).  </li> <li>Export traces and metrics to Grafana Cloud endpoints.  </li> </ul> </li> <li> <p>Remove redundant in-cluster components </p> <ul> <li>No need for Prometheus statefulset, Loki statefulset, Grafana deployment, or Alertmanager.  </li> <li>Keep kube-state-metrics and node exporter, since they are needed for scraping.  </li> </ul> </li> <li> <p>Configure dashboards and alerting in Grafana Cloud </p> <ul> <li>Import Kubernetes dashboards (pre-built).  </li> <li>Define alert rules centrally in Grafana Cloud.  </li> <li>Integrate notification channels (PagerDuty, Slack, Teams, email).  </li> </ul> </li> <li> <p>Secure connections </p> <ul> <li>Use Grafana Cloud TLS endpoints.  </li> <li>Store API keys as Kubernetes secrets.  </li> <li>Apply RBAC to agents and collectors.  </li> </ul> </li> </ol>"},{"location":"2-project/setup/#trade-offs","title":"Trade-offs","text":"<p>Advantages</p> <ul> <li>No stateful services to manage in-cluster.</li> <li>Scalability and HA are handled by Grafana Cloud.</li> <li>Integrated UI for metrics, logs, traces, and alerts.</li> <li>Faster onboarding and less operational risk.</li> </ul> <p>Disadvantages</p> <ul> <li>Vendor lock-in to Grafana Cloud APIs and billing model.</li> <li>Costs scale with data ingestion volume.</li> <li>Less control over retention and storage backends.</li> <li>Alerts require re-implementation in Grafana Cloud (cannot reuse Alertmanager config directly).</li> <li>If compliance requires on-prem retention, this may fail audits.</li> </ul>"},{"location":"2-project/setup/#adding-sentry","title":"Adding Sentry","text":""},{"location":"2-project/setup/#what-grafana-cloud-covers","title":"What Grafana Cloud covers","text":"<ul> <li>Infrastructure metrics (CPU, memory, node, pod health).</li> <li>Application metrics (via Prometheus exporters or OpenTelemetry).</li> <li>Logs (via Loki).</li> <li>Traces (via Tempo).</li> <li>Alerting and dashboards across metrics, logs, traces.</li> </ul> <p>This gives a wide view of system health and performance.</p>"},{"location":"2-project/setup/#what-sentry-covers","title":"What Sentry covers","text":"<ul> <li>Error monitoring and crash reporting at application level.</li> <li>Contextual stack traces: full code paths, local variables, user sessions.</li> <li>Release tracking: errors linked to git commits and releases.</li> <li>User impact analysis: how many users are affected by an error.</li> <li>Frontend and mobile coverage: JavaScript, iOS, Android SDKs that Grafana does not provide out of the box.</li> </ul>"},{"location":"2-project/setup/#trade-offs_1","title":"Trade-offs","text":"<ul> <li> <p>You can approximate some of Sentry\u2019s functions with OpenTelemetry tracing + Grafana Tempo, but:</p> </li> <li> <p>You will not get the same developer-friendly stack traces.</p> </li> <li>You will not get release/version tracking without extra work.</li> <li>You will not get automatic issue grouping and user impact analysis.</li> <li>If you only care about infra + service health, Sentry is redundant.</li> <li>If you need application-level error insight (especially for frontend and user-facing code), Sentry remains valuable.</li> </ul>"},{"location":"2-project/setup/#practical-setup","title":"Practical setup","text":"<ul> <li>Keep Grafana Cloud (metrics/logs/traces/infra alerting).</li> <li>Use Sentry specifically for application exceptions and end-user error reporting.</li> <li> <p>Link them:</p> </li> <li> <p>Send Sentry issues into Grafana alerting or PagerDuty.</p> </li> <li>Add trace IDs in both Sentry and OpenTelemetry spans so developers can pivot between them.</li> </ul> <p>Integration is done at two layers:</p> <ol> <li>Application layer (code instrumentation) \u2014 Sentry SDK inside Django.</li> <li>Observability layer (linking Sentry to Grafana Cloud) \u2014 connect Sentry issues with Grafana Cloud traces/logs via trace IDs.</li> </ol>"},{"location":"2-project/setup/#1-application-layer-django-sentry","title":"1. Application layer: Django + Sentry","text":"<p>Install the SDK:</p> <pre><code>pip install --upgrade sentry-sdk\n</code></pre> <p>Minimal safe configuration in <code>settings.py</code>:</p> <pre><code>import sentry_sdk\nfrom sentry_sdk.integrations.django import DjangoIntegration\nfrom sentry_sdk.integrations.celery import CeleryIntegration\nfrom sentry_sdk.integrations.logging import LoggingIntegration\nimport os\n\nsentry_sdk.init(\n    dsn=os.environ.get(\"SENTRY_DSN\"),  # DSN from Sentry project settings\n    integrations=[\n        DjangoIntegration(),\n        CeleryIntegration(),  # include if Celery is used\n        LoggingIntegration(  # capture logs as breadcrumbs\n            level=None,       # disable default logging capture\n            event_level=\"ERROR\",  # send only errors as events\n        ),\n    ],\n    environment=os.environ.get(\"APP_ENV\", \"production\"),\n    release=os.environ.get(\"GIT_COMMIT_SHA\", \"unknown\"),  # track release\n    traces_sample_rate=0.1,  # adjust rate for performance monitoring\n    send_default_pii=False,  # protect user data unless explicitly needed\n)\n</code></pre>"},{"location":"2-project/setup/#security-and-performance-considerations","title":"Security and performance considerations","text":"<ul> <li><code>send_default_pii=False</code> ensures no sensitive PII is leaked.</li> <li>Control sampling via <code>traces_sample_rate</code> to manage ingestion costs.</li> <li>Always inject <code>release</code> and <code>environment</code> for issue grouping.</li> <li>Store DSN in Kubernetes Secrets, not in code.</li> </ul>"},{"location":"2-project/setup/#2-observability-layer-linking-sentry-and-grafana-cloud","title":"2. Observability layer: Linking Sentry and Grafana Cloud","text":"<p>The goal is correlation. Grafana Cloud handles metrics/logs/traces; Sentry handles exceptions. To connect them:</p>"},{"location":"2-project/setup/#a-enable-distributed-tracing","title":"a. Enable distributed tracing","text":"<ul> <li>Use Sentry performance monitoring with Django.</li> <li> <p>If you also instrument your Django API with OpenTelemetry, you can propagate trace IDs so that a request has both:</p> </li> <li> <p>A trace in Grafana Cloud Tempo.</p> </li> <li>An error in Sentry referencing the same trace ID.</li> </ul> <p>Example middleware to inject the OTel trace ID into Sentry context:</p> <pre><code>from sentry_sdk import configure_scope\nfrom opentelemetry import trace\n\nclass TraceIdMiddleware:\n    def __init__(self, get_response):\n        self.get_response = get_response\n\n    def __call__(self, request):\n        tracer = trace.get_tracer(__name__)\n        span = trace.get_current_span()\n        trace_id = span.get_span_context().trace_id\n        if trace_id:\n            with configure_scope() as scope:\n                scope.set_tag(\"otel_trace_id\", format(trace_id, \"032x\"))\n        return self.get_response(request)\n</code></pre> <p>Now an exception in Sentry will include the OTel trace ID. In Grafana Cloud you can query traces by ID and cross-link.</p>"},{"location":"2-project/setup/#b-alerts-integration","title":"b. Alerts integration","text":"<ul> <li>Configure Sentry alert rules (e.g. \u201cMore than 50 errors in 5 minutes\u201d).</li> <li>Forward them to the same incident pipeline as Grafana Cloud (Slack, PagerDuty, OpsGenie).</li> <li>Result: both infra and application issues flow to the same channel.</li> </ul>"},{"location":"2-project/setup/#c-dashboards","title":"c. Dashboards","text":"<ul> <li>Sentry has its own UI.</li> <li>For unified view: add Sentry plugin datasource to Grafana, or embed Sentry issue widgets in Grafana dashboards.</li> </ul>"},{"location":"2-project/setup/#3-kubernetes-deployment-steps","title":"3. Kubernetes deployment steps","text":"<ol> <li> <p>Provision Sentry project \u2192 get DSN.</p> </li> <li> <p>Create Kubernetes Secret with DSN, e.g.:</p> </li> </ol> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: sentry-dsn\ntype: Opaque\nstringData:\n  SENTRY_DSN: \"https://public_key@o0.ingest.sentry.io/0\"\n</code></pre> <ol> <li> <p>Inject into Django Deployment via environment variable.</p> </li> <li> <p>Redeploy Django pods.</p> </li> <li> <p>Confirm events appear in Sentry dashboard.</p> </li> <li> <p>Validate cross-linking by checking that <code>otel_trace_id</code> tags appear in Sentry issues and can be matched with Grafana Cloud Tempo traces.</p> </li> </ol>"},{"location":"2-project/setup/#outcome","title":"Outcome","text":"<ul> <li>Grafana Cloud handles metrics, logs, distributed traces, and alerting.</li> <li>Sentry handles rich error context, stack traces, and release tracking.</li> <li>Trace IDs bridge them, so developers can pivot from an API error in Sentry to the full request trace in Grafana Cloud.</li> </ul>"},{"location":"2-project/tasks/0-overview/","title":"Overview","text":"<p>This Taskfile defines automation tasks to simplify development workflows and ensure consistency across environments.</p> <p>It abstracts repetitive shell commands into named tasks you can run with:</p> <pre><code>task &lt;task-name&gt; # runs a task\n</code></pre> <p>You can list all available tasks with:</p> <pre><code>task --list-all\n</code></pre> <p>For detailed details about taskfile use:</p> <ul> <li>Main Taskfile</li> <li>GitFlow Taskfile</li> </ul>"},{"location":"2-project/tasks/0-overview/#contact","title":"Contact","text":"<p>Questions or issues with GitFlow setup? Reach out via GitHub Issues or email at your.email@example.com.</p>"},{"location":"2-project/tasks/1-main-taskfile/","title":"Taskfile Documentation","text":"<p>This document explains the structure, conventions, and usage of the main <code>Taskfile.yml</code>. It serves as the primary automation entrypoint for development, deployment, monitoring, and utility workflows in this project.</p>"},{"location":"2-project/tasks/1-main-taskfile/#purpose","title":"Purpose","text":"<p>The Taskfile provides a consistent command-line interface for common project operations. It eliminates the need to memorise long <code>kubectl</code>, <code>helm</code>, or <code>docker</code> commands, ensures reproducibility, and encodes conventions (naming, namespaces, repo URLs, etc.) in a single place.</p> <p>All tasks can be executed with:</p> <pre><code>task &lt;task-name&gt;\n</code></pre>"},{"location":"2-project/tasks/1-main-taskfile/#global-configuration","title":"Global Configuration","text":""},{"location":"2-project/tasks/1-main-taskfile/#version","title":"Version","text":"<p>The Taskfile uses version 3 syntax.</p>"},{"location":"2-project/tasks/1-main-taskfile/#output","title":"Output","text":"<pre><code>output: prefixed\n</code></pre> <p>Logs are prefixed with task names to make parallel output easier to follow.</p>"},{"location":"2-project/tasks/1-main-taskfile/#environment","title":"Environment","text":"<ul> <li><code>.env</code> and <code>.env.local</code> files are automatically loaded.</li> <li>Global environment variables (<code>ENV</code>, <code>DEBUG</code>) can be overridden per-task.</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#variables","title":"Variables","text":"<p>Several key variables are declared for reuse across tasks:</p> <ul> <li> <p>Cluster and namespace:</p> </li> <li> <p><code>KIND_CLUSTER_NAME</code>: Kind cluster name</p> </li> <li><code>DEV_CLUSTER</code>: Development cluster logical name</li> <li> <p><code>DEV_NS</code>: Kubernetes namespace for monitoring</p> </li> <li> <p>Services &amp; ports:</p> </li> <li> <p><code>PROM_SVC</code>, <code>GRAF_SVC</code>, <code>APP_SVC</code>, <code>ALERTM_SVC</code></p> </li> <li> <p><code>PROM_PORT</code>, <code>APP_PORT</code>, <code>ALERTM_PORT</code>, <code>GRAF_PORT</code></p> </li> <li> <p>Helm:</p> </li> <li> <p><code>HELM_REPO_URL</code>, <code>HELM_CHART_NAME</code>, <code>CUSTOM_HELM_REPO_NAME</code>, <code>CUSTOM_HELM_CHART_NAME</code></p> </li> <li> <p>Values files for Helm (<code>FINAL_HELM_VALUES_FILE</code>, <code>READ_HELM_VALUES_FILE</code>)</p> </li> <li> <p>Metadata:</p> </li> <li> <p><code>PROJECT_NAME</code>, <code>TIMESTAMP</code> (dynamic), and app Docker image name.</p> </li> </ul> <p>This ensures one change in variables propagates everywhere (DRY principle).</p>"},{"location":"2-project/tasks/1-main-taskfile/#includes","title":"Includes","text":"<pre><code>includes:\n  common:\n    taskfile: ./Taskfile.gitflow.yaml\n    flatten: true\n</code></pre> <p>A shared GitFlow Taskfile is included, so git-related automation is accessible directly without namespace prefixes.</p>"},{"location":"2-project/tasks/1-main-taskfile/#core-tasks","title":"Core Tasks","text":""},{"location":"2-project/tasks/1-main-taskfile/#default","title":"Default","text":"<p>Lists all tasks:</p> <pre><code>task\n</code></pre>"},{"location":"2-project/tasks/1-main-taskfile/#setup-development","title":"Setup &amp; Development","text":"<ul> <li><code>setup</code>: Creates cluster, loads images, installs Prometheus via Helm, and deploys the app.</li> <li><code>dev</code>: Starts development services, retrieves Grafana credentials, and forwards ports.</li> <li><code>create-cluster-dev</code>: Creates Kind cluster, switches context, creates namespace, and sets it active.</li> <li><code>prod</code>: Placeholder for production deployment pipeline.</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#monitoring-observability","title":"Monitoring &amp; Observability","text":"<ul> <li> <p><code>helm-install-prom</code>: Adds Helm repo, installs Prometheus/Grafana/Alertmanager stack, saves chart values.</p> </li> <li> <p><code>helm-upgrade-prom</code>: Upgrades the stack with current values.</p> </li> <li> <p><code>prom-helm-values</code>: Dumps Helm chart values for inspection.</p> </li> <li> <p>Port forward tasks:</p> </li> <li> <p><code>port-fwd-prom</code>, <code>port-fwd-app</code>, <code>port-fwd-alertm</code>, <code>port-fwd-graf</code></p> </li> <li> <p><code>get-graf-passwd</code>: Fetches Grafana admin password from Kubernetes secret.</p> </li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#application-deployment","title":"Application Deployment","text":"<ul> <li><code>deploy-app</code>: First-time creation of manifests from <code>k8s/</code>.</li> <li><code>apply-app</code>: Applies updates to manifests.</li> <li><code>delete-app</code>: Removes app resources.</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#system-info","title":"System &amp; Info","text":"<ul> <li><code>ports</code>: Lists open ports.</li> <li><code>info</code>: Prints key service URLs.</li> <li><code>status</code>: Runs <code>kubectl get all</code> in the namespace.</li> <li><code>versions</code>: Uses <code>mike list</code> to check docs versions.</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#cleanup","title":"Cleanup","text":"<ul> <li><code>cleanup-dev</code>: Tears down only development stack (Helm release, Kind cluster, k8s resources, repo references, images). Designed to fail gracefully if resources are missing.</li> <li><code>cleanup-prod</code>: Placeholder for production cleanup.</li> <li><code>cleanup-all</code>: Invokes both dev and prod cleanup.</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#utilities","title":"Utilities","text":""},{"location":"2-project/tasks/1-main-taskfile/#kind","title":"Kind","text":"<ul> <li><code>kind-load-images</code>: Ensures application image is pulled locally and loaded into Kind cluster (faster than registry pulls).</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#documentation","title":"Documentation","text":"<ul> <li><code>docs</code>: Runs <code>mkdocs serve</code> via Poetry, serving docs at http://127.0.0.1:8000/docs/.</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#compression","title":"Compression","text":"<ul> <li><code>compress</code>: Downscales and compresses MP4 to <code>assets/demo-video-small.mp4</code>. Supports runtime overrides (<code>crf</code>, <code>preset</code>).</li> <li><code>compress-gif</code>: Optimises and compresses GIFs into <code>assets/demo-video-small.gif</code>. Generates and applies a palette for quality.</li> <li><code>mkdir-assets</code>: Ensures <code>assets/</code> directory exists on Linux/macOS or Windows before compression tasks.</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#workflow-examples","title":"Workflow Examples","text":"<ol> <li>Bootstrap monitoring stack:</li> </ol> <pre><code>task setup\n</code></pre> <ol> <li>Iterate locally:</li> </ol> <pre><code>task dev\n</code></pre> <ol> <li>View monitoring endpoints:</li> </ol> <pre><code>task info\n</code></pre> <ol> <li>Tear down environment:</li> </ol> <pre><code>task cleanup-dev\n</code></pre>"},{"location":"2-project/tasks/1-main-taskfile/#design-conventions","title":"Design Conventions","text":"<ul> <li>Fail gracefully: Tasks often use <code>|| echo \"error ...\"</code> to avoid halting entire pipelines.</li> <li>Idempotency: Many tasks can be rerun without harm (e.g., <code>kubectl create namespace</code>).</li> <li>Cross-platform: Some tasks (<code>mkdir-assets</code>) include OS-specific logic.</li> <li>Separation of concerns: App vs. infra vs. docs tasks are grouped logically.</li> <li>DRY configuration: Variables centralise cluster, service, and chart settings.</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#notes-recommendations","title":"Notes &amp; Recommendations","text":"<ul> <li>To check all available tasks:</li> </ul> <p><pre><code>task --list-all\n</code></pre> * Always verify Helm values files (<code>k8s/values</code> vs <code>k8s/read_values</code>) before upgrades. * Use port-forward tasks only for local debugging. For real environments, prefer ingress or LoadBalancer services. * <code>prod</code>, <code>cleanup-prod</code>, and other stubs are intentionally left for extension in real deployments.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/","title":"GitFlow Taskfile Overview","text":"<p>This page explains the structure and functionality of the <code>Taskfile.gitflow.yml</code> file, which automates a standardized Git workflow using Git Flow conventions. This taskfile is designed to simplify and formalize branching, releasing, and hotfixing in projects that follow the GitFlow methodology.</p> <p>It is optional to use gitflow.</p> <p>If you do not want to use it, you can remove the <code>Taskfile.gitflow.yml</code> file and unlink it from the <code>Taskfile.yaml</code> file (remove the <code>includes</code> section). If you cannot find the section use <code>CTRL + F</code> to search for Taskfile.yaml.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#what-is-git-flow","title":"What is Git Flow?","text":"<p>Git Flow is a branching strategy that separates feature development from production releases. It introduces long-lived branches like <code>main</code> and <code>develop</code>, as well as temporary branches for features, releases, and hotfixes.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#purpose-of-this-taskfile","title":"Purpose of This Taskfile","text":"<p>The <code>Taskfile.gitflow.yml</code> automates repetitive Git Flow actions using the <code>task</code> CLI tool. It allows you to:</p> <ul> <li>Initialize a Git Flow structure with default branches and prefixes</li> <li>Create and finish feature branches</li> <li>Create release and hotfix branches</li> <li>Push and merge code with consistent naming and flow</li> <li>Eliminate manual mistakes in branch naming or merging</li> </ul> <p>This is especially useful in teams or long-running solo projects where structured release cycles are important.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#what-this-taskfile-automates","title":"What This Taskfile Automates","text":"<p>Here\u2019s a breakdown of what\u2019s covered:</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#1-initialization","title":"1. Initialization","text":"<ul> <li>Sets up Git Flow with <code>main</code> as the production branch and <code>develop</code> for ongoing work.</li> <li>Configures standard prefixes (<code>feature/</code>, <code>release/</code>, <code>hotfix/</code>, etc.).</li> <li>Ensures required branches (<code>main</code>, <code>develop</code>) exist locally and remotely.</li> <li>Optionally initializes the <code>gh-pages</code> branch for documentation deployments.</li> </ul> <p>This is typically run once at the start of the project using <code>task -t Taskfile.gitflow.yml init</code>.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#2-feature-branch-management","title":"2. Feature Branch Management","text":"<ul> <li>Start a new feature branch from <code>develop</code></li> <li>Finish a feature by merging it back into <code>develop</code></li> <li>Automatically push changes to the remote</li> <li>Prevents common mistakes like forgetting to push or rebase</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#3-release-branch-management","title":"3. Release Branch Management","text":"<ul> <li>Create a release branch off <code>develop</code></li> <li>Optionally tag a version</li> <li>Merge into <code>main</code> and <code>develop</code></li> <li>Clean up the release branch</li> <li>Pushes changes and tags to the remote</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#4-hotfix-branch-management","title":"4. Hotfix Branch Management","text":"<ul> <li>Create a hotfix directly off <code>main</code> (for production issues)</li> <li>Merge back into both <code>main</code> and <code>develop</code></li> <li>Optionally tag the hotfix release</li> <li>Push changes and remove local branches</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#5-branch-cleanup-and-syncing","title":"5. Branch Cleanup and Syncing","text":"<ul> <li>Deletes local feature/release branches after merging</li> <li>Pulls and syncs remote branches as needed</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#typical-usage-flow","title":"Typical Usage Flow","text":"<ol> <li> <p>Initialize GitFlow structure <pre><code>task init\n</code></pre></p> </li> <li> <p>Start a new feature <pre><code>task feature:start name=\"add-login\"\n</code></pre></p> </li> <li> <p>Finish a feature <pre><code>task feature:finish name=\"add-login\"\n</code></pre></p> </li> <li> <p>Start a release <pre><code>task release:start version=\"1.0.0\"\n</code></pre></p> </li> <li> <p>Start a hotfix <pre><code>task hotfix:start version=\"1.0.1\"\n</code></pre></p> </li> <li> <p>Finish a release <pre><code>task release:finish version=\"1.0.0\"\n</code></pre></p> </li> <li> <p>Finish a hotfix <pre><code>task hotfix:finish version=\"1.0.1\"\n</code></pre></p> </li> </ol>"},{"location":"2-project/tasks/2-gitflow-taskfile/#when-should-you-use-this","title":"When Should You Use This?","text":"<p>Use this taskfile when:</p> <ul> <li>You want consistent branch names and GitFlow discipline</li> <li>You're working in long-lived projects that ship versioned releases</li> <li>You have documentation (e.g. via <code>mike</code>) that needs coordinated tagging</li> <li>You want to automate repetitive Git steps safely</li> </ul> <p>Avoid using it if:</p> <ul> <li>Your workflow is trunk-based (i.e., no <code>develop</code>)</li> <li>You're doing rapid prototyping without versioning</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#notes","title":"Notes","text":"<ul> <li>This taskfile assumes Git is already initialized and the remote origin is set.</li> <li>It is safe to re-run <code>init</code>; it won\u2019t overwrite existing GitFlow config.</li> <li>The file uses <code>{{.VAR_NAME}}</code> placeholders \u2014 these are defined in the task's command-line usage.</li> <li>You can see available tasks by running:</li> </ul> <pre><code>task --list-all\n</code></pre>"},{"location":"2-project/tasks/2-gitflow-taskfile/#related-docs","title":"Related Docs","text":"<ul> <li>Main Taskfile Overview</li> <li>Getting Started</li> <li>Architecture</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#contact","title":"Contact","text":"<p>Questions or issues with GitFlow setup? Reach out via GitHub Issues or email at seannjela@outlook.com.</p>"},{"location":"3-troubleshooting/0-overview/","title":"Troubleshooting Guide Overview","text":"<p>Welcome to the troubleshooting section of this documentation. This guide exists to help you diagnose and resolve common issues that may arise while using or setting up this project.</p> <p>Use the search bar at the top of this page to type keywords related to your issue (e.g., docker, cluster, permissions) and quickly find relevant entries.</p>"},{"location":"3-troubleshooting/0-overview/#what-youll-find-here","title":"What You'll Find Here","text":"<p>Each page in this section covers a specific issue or category of problems. These are meant to be: - Concise - Actionable - Focused on real problems encountered during development or deployment</p> <p>You can browse specific problem pages here:</p> <ul> <li>Problem 1</li> <li>Problem 2</li> <li>(More will be added as new issues are documented)</li> </ul> <p>Important Disclaimer</p> <p>This is a personal documentation site. I am maintaining it solo and cannot guarantee that every issue is fully documented or resolved. If you don\u2019t find a solution here, don\u2019t panic \u2014 most tools used in this project (e.g., Docker, Kubernetes, Terraform, Devbox) are widely adopted and well-supported. Try these resources first:</p> <ol> <li>ChatGPT or another AI assistant \u2013 Quick answers and guided debugging  </li> <li>YouTube \u2013 Visual walkthroughs for complex tools or errors  </li> <li>Google \u2013 Forums, GitHub Issues, and StackOverflow posts are often goldmines  </li> </ol>"},{"location":"3-troubleshooting/0-overview/#pro-tip","title":"Pro Tip","text":"<p>When searching using the search bar above, include the name of the tool or parts of the error message (in quotes if exact), e.g.:</p> <p>\"helm install\" or \"helm\" \"chart not found\" or \"not found\" \"terraform apply\" or \"terraform\" \"invalid provider configuration\" or \"provider not found\" \"kubectl apply\" or \"kubectl\" \"namespace not found\" or \"namespace does not exist\"</p> <p>Thank you for your patience and initiative \u2014 the more we learn from problems, the better this documentation will become.</p>"},{"location":"3-troubleshooting/1-problem1/","title":"Problem Title (Short and Specific)","text":"<p>A short one-liner summary of the issue, e.g., \u201cHelm chart fails with \u2018chart not found\u2019 error\u201d.</p>"},{"location":"3-troubleshooting/1-problem1/#context","title":"Context","text":"<p>Briefly describe when/where this issue happens: - What tool was being used? - What command was run? - What environment (e.g., Devbox, Docker, local cluster)? - Optional: Any preconditions or relevant setup</p>"},{"location":"3-troubleshooting/1-problem1/#symptoms","title":"Symptoms","text":"<p>List or describe the symptoms: - Error messages (you can add real output later) - Logs or console behavior - What \"broke\" or stopped working</p>"},{"location":"3-troubleshooting/1-problem1/#possible-causes","title":"Possible Causes","text":"<p>List 1\u20133 likely causes of this issue: - Misconfiguration - Dependency/version mismatch - Network or permissions issue</p>"},{"location":"3-troubleshooting/1-problem1/#resolution-if-available","title":"Resolution (If Available)","text":"<p>Leave this blank until you've confirmed a fix.</p>"},{"location":"3-troubleshooting/1-problem1/#workarounds-optional","title":"Workarounds (Optional)","text":"<p>Alternative approaches or partial fixes that helped during debugging.</p>"},{"location":"3-troubleshooting/1-problem1/#external-references","title":"External References","text":"<p>Useful links, docs, or forum threads: - Stack Overflow Thread - Official Docs - GitHub Issue</p>"},{"location":"3-troubleshooting/1-problem1/#notes","title":"Notes","text":"<ul> <li>Is this a recurring issue?</li> <li>Does it affect production or just local dev?</li> <li>Can this be caught with a precheck or task later?</li> </ul>"},{"location":"3-troubleshooting/2-problem2/","title":"Problem Title (Short and Specific)","text":"<p>A short one-liner summary of the issue, e.g., \u201cHelm chart fails with \u2018chart not found\u2019 error\u201d.</p>"},{"location":"3-troubleshooting/2-problem2/#context","title":"Context","text":"<p>Briefly describe when/where this issue happens: - What tool was being used? - What command was run? - What environment (e.g., Devbox, Docker, local cluster)? - Optional: Any preconditions or relevant setup</p>"},{"location":"3-troubleshooting/2-problem2/#symptoms","title":"Symptoms","text":"<p>List or describe the symptoms: - Error messages (you can add real output later) - Logs or console behavior - What \"broke\" or stopped working</p>"},{"location":"3-troubleshooting/2-problem2/#possible-causes","title":"Possible Causes","text":"<p>List 1\u20133 likely causes of this issue: - Misconfiguration - Dependency/version mismatch - Network or permissions issue</p>"},{"location":"3-troubleshooting/2-problem2/#resolution-if-available","title":"Resolution (If Available)","text":"<p>Leave this blank until you've confirmed a fix.</p>"},{"location":"3-troubleshooting/2-problem2/#workarounds-optional","title":"Workarounds (Optional)","text":"<p>Alternative approaches or partial fixes that helped during debugging.</p>"},{"location":"3-troubleshooting/2-problem2/#external-references","title":"External References","text":"<p>Useful links, docs, or forum threads: - Stack Overflow Thread - Official Docs - GitHub Issue</p>"},{"location":"3-troubleshooting/2-problem2/#notes","title":"Notes","text":"<ul> <li>Is this a recurring issue?</li> <li>Does it affect production or just local dev?</li> <li>Can this be caught with a precheck or task later?</li> </ul>"},{"location":"4-about/0-about/","title":"About Me","text":"<p>Dang, you really wanna know huh?</p> <p>I\u2019m Sean Njela, DevOpsSean. I'm a developer, engineer, and lifelong learner documenting my personal and professional projects.</p> <p>This site serves as a central hub for my technical work, built using MkDocs and organized to reflect real-world implementations, lessons learned, and ongoing exploration in areas like DevOps, infrastructure, automation, and system design.</p>"},{"location":"4-about/0-about/#why-this-exists","title":"Why This Exists","text":"<p>This documentation is part of an ongoing effort to:</p> <ul> <li>Capture complex project setups in a reusable, referenceable format</li> <li>Practice clear technical communication</li> <li>Save future-me from future-headaches</li> <li>Share knowledge with others who might stumble across this work</li> </ul> <p>Whether you're here to learn, debug, borrow ideas, or just browse, you're welcome.</p>"},{"location":"4-about/0-about/#tools-and-tech-i-often-work-with","title":"Tools and Tech I Often Work With","text":"<p>Some of the technologies you'll find across these projects:</p> <ul> <li>Containers: Docker, Kubernetes, Kind</li> <li>Infrastructure: Terraform, Helm, Devbox</li> <li>Automation: Taskfile, Make, CI/CD workflows</li> <li>Docs: MkDocs, markdown, GitHub Pages</li> <li>Languages: Python, Bash, YAML</li> </ul> <p>This stack evolves as I experiment and learn \u2014 not every project will use everything.</p>"},{"location":"4-about/0-about/#about-this-site","title":"About This Site","text":"<ul> <li>Built with <code>mkdocs-material</code></li> <li>Versioned using <code>mike</code></li> <li>Fully local-first and Git-managed</li> <li>Organized by topic, not tool \u2014 documentation follows the problem or pattern</li> </ul>"},{"location":"4-about/0-about/#contact","title":"Contact","text":"<p>I\u2019m always open to questions, feedback, or conversation:</p> <ul> <li>GitHub: @sean-njela</li> <li>Email: sean.njela@gmail.com</li> <li>Twitter/X: @devopssean</li> </ul> <p>Thanks for visiting !</p>"}]}